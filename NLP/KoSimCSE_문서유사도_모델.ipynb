{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 라이브러리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import os, sys\n",
    "sys.path.append(os.path.dirname(os.path.dirname(os.path.dirname(os.path.abspath(__file__)))))\n",
    "\n",
    "import torch\n",
    "import pandas as pd\n",
    "from transformers import AutoModel, AutoTokenizer\n",
    "from google.cloud import storage"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 클래스"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KoSimCSE:\n",
    "    \"\"\"\n",
    "    KoSimCSE 텍스트 유사도 모델 활용\n",
    "    텍스트 Embedding 전환\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    def __init__(self) -> None:\n",
    "        self.MODEL_NAME='BM-K/KoSimCSE-roberta-multitask' # ==> 모델 이름 정의\n",
    "        self.BUCKET_NAME='law-search'  # ==> GCS 저장소 bucket name\n",
    "\n",
    "\n",
    "    def convert_text_to_embedding(self, sub_df: pd.DataFrame) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Text 데이터 embedding 데이터 변환\n",
    "        \"\"\"\n",
    "        # 컬럼 변수\n",
    "        col_embedding='embedding'\n",
    "\n",
    "        # 모델 & 토크나이저\n",
    "        model=AutoModel.from_pretrained(self.MODEL_NAME)\n",
    "        tokenizer=AutoTokenizer.from_pretrained(self.MODEL_NAME)\n",
    "\n",
    "        #Mean Pooling - Take attention mask into account for correct averaging\n",
    "        def mean_pooling(model_output, attention_mask):\n",
    "            token_embeddings = model_output[0] #First element of model_output contains all token embeddings\n",
    "            input_mask_expanded = attention_mask.unsqueeze(-1).expand(token_embeddings.size()).float()\n",
    "            return torch.sum(token_embeddings * input_mask_expanded, 1) / torch.clamp(input_mask_expanded.sum(1), min=1e-9)\n",
    "\n",
    "        embedding_list=[]\n",
    "        for _, row in sub_df.iterrows():\n",
    "            law_text=row.law\n",
    "            \n",
    "            # 전처리 pattern 및 전처리 진행\n",
    "            pattern=r'\\<(.*?)\\>'\n",
    "            prepro_text=re.sub(pattern, '', law_text).strip()\n",
    "\n",
    "            # 특수기호 제거 및 띄어쓰기 반복 변형\n",
    "            prepro_text=re.sub(r' +', ' ',re.sub(r'[^가-힣a-zA-Z0-9]', ' ', prepro_text)).strip()\n",
    "\n",
    "            # Tokenize sentences\n",
    "            encoded_input = tokenizer(prepro_text, padding=True, truncation=True, return_tensors='pt')\n",
    "\n",
    "            # Compute token embeddings\n",
    "            with torch.no_grad():\n",
    "                model_output = model(**encoded_input)\n",
    "            \n",
    "            # Perform pooling. In this case, mean pooling.\n",
    "            sentence_embeddings = mean_pooling(model_output, encoded_input['attention_mask'])\n",
    "            # 데이터 정립\n",
    "            embedding_list.append(sentence_embeddings[0].tolist())\n",
    "\n",
    "        prepro_sub_df=sub_df.copy()\n",
    "        prepro_sub_df[col_embedding]=embedding_list\n",
    "        \n",
    "        return prepro_sub_df\n",
    "\n",
    "    \n",
    "    def local_to_gcs(self, file_name):\n",
    "        \"\"\"\n",
    "        로컬에 저장된 파일 GCS bucket에 업로드\n",
    "        \"\"\"\n",
    "        storage_client = storage.Client()\n",
    "        bucket=storage_client.bucket(self.BUCKET_NAME)\n",
    "        local_path=os.path.join(os.path.abspath(os.getcwd()), file_name)  # local에서 업로드할 파일 경로\n",
    "        gcs_upload_path= \"law/\"+file_name   # 업로드 할 GCS 경로\n",
    "        blob=bucket.blob(gcs_upload_path)   # 업로드 할 bucket 세팅\n",
    "        blob.upload_from_filename(local_path)   # 업로드\n",
    "        print(f'[INFO] Local to GCS bucket Upload completely -> file : {local_path}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kosim_cls=KoSimCSE()\n",
    "test_filnm = \"./test.csv\"\n",
    "test_df = pd.read_csv(test_filnm)\n",
    "prv_embedding_df=kosim_cls.convert_text_to_embedding(test_df)    # embedding 데이터 만들기\n",
    "prv_file_name='test_embedding.csv'\n",
    "prv_embedding_df.to_csv(prv_file_name, index=False, encoding='utf-8')   # embedding 데이터 저장\n",
    "kosim_cls.local_to_gcs(prv_file_name)   # embedding 데이터 업로드\n",
    "os.remove(prv_file_name)    # remove csv file from local\n",
    "print(f\"[INFO] Remove {prv_file_name} file completely\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_py38",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ba4a0d203aef4d4d68270416999e5a88481b27d40dd87df20cd967aefb9b99ea"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
