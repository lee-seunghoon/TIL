{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 라이브러리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "from konlpy.tag import Okt\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# matplotlib 그래프 속성 설정\n",
    "plt.rcParams['font.family'] = 'Malgun Gothic'\n",
    "plt.rcParams['figure.figsize'] = (12,16)\n",
    "plt.rcParams['font.size'] = 20\n",
    "\n",
    "# 그래프 그릴 때 마이너스(-) 부분도 표시해주기 (로그오즈비 표현을 위해 세팅)\n",
    "plt.rcParams['axes.unicode_minus'] = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 사용자 정의 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 텍스트 전처리\n",
    "def prepro_text(raw_data):\n",
    "\n",
    "    # 특수기호, 영어, 숫자 제거\n",
    "    prepro_texts = re.sub(r'[^가-힣]',' ',str(raw_data))\n",
    "\n",
    "    # 형태소 분석기 생성\n",
    "    okt = Okt()\n",
    "\n",
    "    # 조사와 복수표현 등 필요없는 품사 tag 제거\n",
    "    prepro_word = []\n",
    "    for word, tag in okt.pos(prepro_texts):\n",
    "        if tag not in ['Josa', 'Suffix']:\n",
    "            prepro_word.append(word)\n",
    "    \n",
    "    # 어간 추출 적용\n",
    "    # result = ' '.join(okt.morphs(' '.join(prepro_word), stem=True))\n",
    "\n",
    "    result = ' '.join(prepro_word)\n",
    "\n",
    "    return result\n",
    "\n",
    "\n",
    "# 빈도분석 후 결과 출력\n",
    "def count_analyze(texts, count_vec, color=None, title=None):\n",
    "    \n",
    "    count_vec.fit(texts)\n",
    "    \n",
    "    word_dict = sorted(count_vec.vocabulary_.items())\n",
    "    idx2word = {idx:word for word, idx in word_dict}\n",
    "\n",
    "    total_text = []\n",
    "    total_text.append(' '.join(texts.values))\n",
    "\n",
    "    count_matrix = count_vec.transform(total_text)\n",
    "\n",
    "    count_word = []\n",
    "    count_vector = []\n",
    "\n",
    "    for i in range(20,0,-1):\n",
    "        count_word.append(idx2word[(-count_matrix.toarray()[0]).argsort()[i-1]])\n",
    "        count_vector.append(count_matrix.toarray()[0][(-count_matrix.toarray()[0]).argsort()[i-1]])\n",
    "\n",
    "    # print(count_word)\n",
    "    # print(count_vector)\n",
    "\n",
    "    # plt.barh(count_word, count_vector, color=color)\n",
    "    # plt.yticks(count_word)\n",
    "    # plt.title(f'{title} 빈도 분석')\n",
    "    # plt.show()\n",
    "\n",
    "    return count_word, count_vector\n",
    "\n",
    "\n",
    "# 코사인 유사도 score 추출\n",
    "def cosine_extraction(vec, fit_data, count_words):\n",
    "\n",
    "    # 적합 후 벡터 변화\n",
    "    analysis_vec = vec.fit_transform(fit_data)    \n",
    "\n",
    "    # 빈도분석으로 뽑은 Top10 단어들 하나의 text로\n",
    "    top10_word_vec = vec.transform([' '.join(count_words)])\n",
    "\n",
    "    cosine_sim = cosine_similarity(top10_word_vec, analysis_vec)\n",
    "\n",
    "    cos_sim = fit_data.name\n",
    "\n",
    "    cosine_df = pd.DataFrame({\n",
    "        'h_id' : fit_data.index.values,\n",
    "        cos_sim : cosine_sim[0]\n",
    "    })\n",
    "    #fit_cosine_df['코사인 유사도'] = fit_cosine_df['코사인 유사도'].map(lambda x: round(x,3))\n",
    "    #fit_cosine_df['rank'] = fit_cosine_df['코사인 유사도'].rank(ascending=False).astype(np.int64)\n",
    "\n",
    "    return cosine_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 데이터 로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_row', 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'C:\\\\Users\\\\GOOD\\\\Desktop\\\\이승훈\\\\hjgrace\\\\신사업프로젝트\\\\히든그레이스_자소서_텍스트분석_data.xlsx'\n",
    "df = pd.read_excel(path)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17 label2\n",
      "25 히든그레이스는 어떤 회사인가\n",
      "26 히든그레이스가 보완할 점\n",
      "27 채용 된다면 일할 수 있는 기간, 오래 일하는 데 문제 되는 요소\n"
     ]
    }
   ],
   "source": [
    "# 내가 필요한 데이터 컬럼 index 확인\n",
    "for idx, title in enumerate(df.columns.values):\n",
    "    if title == 'label2':\n",
    "        print(idx, title)\n",
    "    elif title == '히든그레이스는 어떤 회사인가':\n",
    "        print(idx, title)\n",
    "    elif title == '히든그레이스가 보완할 점':\n",
    "        print(idx, title)\n",
    "    elif title == '채용 된다면 일할 수 있는 기간, 오래 일하는 데 문제 되는 요소':\n",
    "        print(idx, title)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 데이터 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 전체 데이터\n",
    "use_df = df.iloc[:,[0,17,25,26,27]]\n",
    "\n",
    "for col in use_df.columns.values[-3:]:\n",
    "    use_df[col] = use_df[col].map(prepro_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 데이터 분리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# label0인 데이터 (새로운 데이터가 포함된)\n",
    "label0_df = use_df[use_df.iloc[:,1]==0]\n",
    "\n",
    "# label1인 데이터 (새로운 데이터가 포함된)\n",
    "label1_df = use_df[use_df.iloc[:,1]==1]\n",
    "label1_df = pd.concat([label1_df, use_df[-3:]], axis=0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 코사인 유사도 추출"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## label0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 코사인 유사도 넣을 dataframe 생성\n",
    "label0_cos_df = pd.DataFrame({\n",
    "    'h_id' : label0_df.index.values,\n",
    "    'name' : label0_df.iloc[:,0].values,\n",
    "    })\n",
    "\n",
    "# 코사인 유사도 추출 & merge\n",
    "for col in label0_df.columns[-3:]:\n",
    "    \n",
    "    # fit할 데이터\n",
    "    fit_data = label0_df[col]\n",
    "    # 불용어사전\n",
    "    stop_words = ['하는', '있는', '하여', '합니다', '하게', '지원', '입니다', '입사', '하겠습니다', '위해', '되었습니다', '싶습니다', '가지', '생각', '통해',\n",
    "                  '회사', '히든', '그레이스', '분야', '해야', '같습니다', '관련', '오래', '하는데', '요소', '되는', '된다면', '있습니다', '하지', '정도', '하고',\n",
    "                  '있을', '만약', '어떤', '때문', '있다고']\n",
    "    # count 벡터라이저\n",
    "    count_vec = CountVectorizer(\n",
    "        stop_words=stop_words,\n",
    "        min_df=2\n",
    "    )\n",
    "    # 빈도분석 결과\n",
    "    label0_word, label0_vec = count_analyze(fit_data, count_vec)\n",
    "    # 코사인 유사도 \n",
    "    cos_df = cosine_extraction(count_vec, fit_data, label0_word)\n",
    "    # merge\n",
    "    label0_cos_df = pd.merge(label0_cos_df, cos_df, on='h_id', how='left')\n",
    "\n",
    "# 전체 평균 구하기\n",
    "label0_cos_df['mean'] = label0_cos_df.iloc[:,2:].mean(axis=1)\n",
    "# 랭킹 구하기\n",
    "label0_cos_df['rank'] = label0_cos_df['mean'].rank(ascending=False).astype(np.int64)\n",
    "\n",
    "label0_cos_df.sort_values(by='rank', axis=0, ascending=True, inplace=True)\n",
    "label0_cos_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## label1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 코사인 유사도 넣을 dataframe 생성\n",
    "label1_cos_df = pd.DataFrame({\n",
    "    'h_id' : label1_df.index.values,\n",
    "    'name' : label1_df.iloc[:,0].values,\n",
    "    })\n",
    "\n",
    "# 코사인 유사도 추출 & merge\n",
    "for col in label1_df.columns[-3:]:\n",
    "    \n",
    "    # fit할 데이터\n",
    "    fit_data = label1_df[col]\n",
    "    # 불용어사전\n",
    "    stop_words = ['하는', '있는', '하여', '합니다', '하게', '지원', '입니다', '입사', '하겠습니다', '위해', '되었습니다', '싶습니다', '가지', '생각', '통해',\n",
    "                  '회사', '히든', '그레이스', '분야', '해야', '같습니다', '관련', '오래', '하는데', '요소', '되는', '된다면', '있습니다', '하지', '정도', '하고',\n",
    "                  '있을', '만약', '어떤', '때문', '있다고']\n",
    "    # count 벡터라이저\n",
    "    count_vec = CountVectorizer(\n",
    "        stop_words=stop_words,\n",
    "        min_df=2\n",
    "    )\n",
    "    # 빈도분석 결과\n",
    "    label0_word, label0_vec = count_analyze(fit_data, count_vec)\n",
    "    # 코사인 유사도 \n",
    "    cos_df = cosine_extraction(count_vec, fit_data, label0_word)\n",
    "    # merge\n",
    "    label1_cos_df = pd.merge(label1_cos_df, cos_df, on='h_id', how='left')\n",
    "\n",
    "# 전체 평균 구하기\n",
    "label1_cos_df['mean'] = label1_cos_df.iloc[:,2:].mean(axis=1)\n",
    "# 랭킹 구하기\n",
    "label1_cos_df['rank'] = label1_cos_df['mean'].rank(ascending=False).astype(np.int64)\n",
    "\n",
    "label1_cos_df.sort_values(by='rank', axis=0, ascending=True, inplace=True)\n",
    "label1_cos_df\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e9ac6c096094207bc2d8717289e29194efa0a9ca38178f105ef07f8209e7d24c"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
