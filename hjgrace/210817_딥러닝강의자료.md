### 뉴런

> - 우리의 뇌는 이전 neuron으로부터 입력신호를 전달받아서 또 다른 신호를 발생시키는 일을 한다.
> - 입력값에 비례해서 출력값을 내보내는 형태가 아니다.
> - 입력값에 가중치(w)를 곱한 후 모두 더해서 특정 함수를 이용하여 thresholde를 넘는지 확인!
> - ==> 임계점을 넘으면 출력값 발생
> - `특정 함수` 란.. Activation Function (`sigmoid`, `softmax` etc.)
> - 하나의 Neuron이 하나의 logistic 이다.



### 이미지 데이터

> - 이미지 이루고 있는 가장 기본 단위 : **`Pixel`** (해상도) ==> 해상도 ⬆️ -> pixel 개수 ⬆️
> - 이미지는 우리가 일반적으로 사용하는 `데카르트 좌표계`와 다른 **`이미지 좌표계`** 를 사용한다.
> - ==> **`Matrix 좌표계 (행렬 좌표계)`**
> - 2차원 이미지(M × N)를 ndarray로 표현 ==> **`pixel [세로(M), 가로(N)]`**
> - ⭐ 세로쪽 아래로 내려갈수록 숫자가 증가한다.

> - **`gray-Image(흑백 이미지)`**
>   - 각 pixel의 값을 0~255 값으로 표현
>     - 1 pixel에 8bit를 사용하기 때문에 2^8 = 256개
>   - 2차원
> - **`color Image(컬러 이미지)`**
>   - 각 pixel에 3개의 channel이 포함
>   - 각 channel은 빛의 3원색 (R,G,B)
>   - **`3차원`**
>   - 💗 Red : 0~255 (8bit) / 💚 Green : 0~255 (8bit) / 💙 Blue : 0~255 (8bit)
>   - `'24bit'` ==> `True Color`
>   - `JPG` file ▶️ 3 channel (RGB)
>   - `PNG` file ▶️ 4 channel (RGB + α) (α:투명도)

```python
# 라이브러리
from PIL import Image
import numpy as np
import matplotlib.pyplot as plt

# 이미지 로드
img_path = '/content/drive/MyDrive/Google Colab/dog.1006.jpg'
img = Image.open(img_path)
plt.imshow(img)
plt.show()

# 이미지를 숫자 pixel값으로 변경
pixel = np.array(img)

# 이미지 size와 shape 확인
print('이미지의 크기 : {}'.format(img.size))
# ==> 이미지의 크기 : (499, 500) == (가로, 세로)

print('이미지의 shape : {}'.format(pixel.shape))
# 이미지의 shape : (500, 499, 3) == (세로길이, 가로, 각 pixel당 rgb 3개 가지고 있다.)

# 실제 값을 한 번 보자
print('x좌표:{}, y좌표:{}인 pixel 값:{}'.format(100,200,pixel[200, 100]))
# x좌표:100, y좌표:200인 pixel 값:[115  96  89] == [R, G, B]
# pixel 값 줄 때 조심하자! pixel[200,100] == pixel[세로(y), 가로(x)]

# 이미지 size 줄여보기
img_resize = img.resize((50, 50))
plt.imshow(img_resize)
plt.show()
```



### 흑백 이미지 변동 방법

#### #1

```python
# 3차원 그대로 사용하는 방법 == 모든 값 평균으로 대체

# 흑백 이미지 3차원 데이터로 표현
# 각 pixel의 RGB값의 평균! 구해서 각각의 R G B 값으로 설정
gray_pixel = pixel.copy()

# y= 세로 / x = 가로
for y range(gray_pixel.shape[0]):
    for x in range(gray_pixel.shape[1]):
        gray_pixel[y,x] = int(np.mean(gray_pixel[y,x]))
        # <<< 해당 pixel의 요소 3개짜리(RGB값) vector
        # 브로드캐스팅 되면서 각 rgb 값이 모두 평균값으로 대체된다.
        # [76 76 76] 모두 이 값으로 setting

plt.imshow(gray_pixel)
plt.show()
```



#### #2

```python
# 2차원으로 흑백 이미지 표현

# rgb 값 중에 1개만 가져와서 그냥 값으로 표현하기 (rgb 값이 vector 벗어나)

gray_2d_pixel  = gray_pixel[:,:,0]
print(gray_2d_pixel.shape) # (426, 640) 2차원

plt.imshow(gray_2d_pixel) 
# plt.imshow()는 3차원 image를 받아서 보여주는거다!
# 그러다보니 cmap 지정 안해주면 아래처럼 이미지가 나온다.
plt.show()

##################################################################

plt.imshow(gray_2d_pixel, cmap='gray') 
plt.show()
# cmap='gray' 이 값을 주면 정상적인 흑백 이미지를 보여준다.
```



### Teachable Machine

> - 파일로 학습 및 평가





### CNN (바닐라 날것의...)

> - 이미지 데이터 전처리

```python
# 라이브러리
import numpy as np
import pandas as pd
import os
import cv2
from sklearn import utils
from sklearn.preprocessing import MinMaxScaler


# 파일 경로
train_dir = '/content/drive/MyDrive/Cat_Dog/cat_dog_small/train'
val_dir = '/content/drive/MyDrive/Cat_Dog/cat_dog_small/validation'
test_dir = '/content/drive/MyDrive/Cat_Dog/cat_dog_small/test'

# labeling 함수 (고양이=0, 개=1)
# img = 파일 이름
def labeling(img):
    class_name = img.split('.')[0]
    if class_name == 'cat': return 0
    elif class_name == 'dog': return 1
    
# 이미지 파일을 pixel data로 바꾸는 함수
def create_train_data(directory):
    
    # label data와 pixel data 담을 변수
    t_data = []
    x_data = []

    cat_dir = os.path.join(directory, 'cats')
    dog_dir = os.path.join(directory, 'dogs')

    total_img = os.listdir(cat_dir) + os.listdir(dog_dir)

    for img in total_img:

        label_data = labeling(img)

        if img.split('.')[0] == 'cat':
              path = os.path.join(cat_dir, img)
        else:
              path = os.path.join(dog_dir, img)

        # 이미지 파일 nd.array로 불러오기 (cv2.imread())
        # 형태만 필요해서 흑백으로 불러오기 (cv2.IMREAD_GRAYSCALE)
        # 이미지 pixel size 조정하기
        img_data = cv2.resize(cv2.imread(path, cv2.IMREAD_GRAYSCALE), (70,70))

        t_data.append(label_data)
        x_data.append(img_data.ravel())
        # ==> img_data 이미지 shape이 (70,70), 즉 2차원
        # ==> 이게 그대로 들어가면 차원 하나 더 있어서 결국 3차원... 그래서 1차원으로 바꿔주기(ravel())

    # labeling Data ==> dataframe으로 만들기
    t_df = pd.DataFrame({
        'label': t_data
    })

    # 이미지 픽셀 data ==> dataframe으로 만들기
    x_df = pd.DataFrame(x_data)

    # 2개 dataframe 합치기 (행 개수가 같아야 한다?)
    df = pd.merge(t_df, x_df, left_index=True, right_index=True)

    # utils.shuffle() ==> pandas dataframe 행을 shuffle 한다.
    shuffled_df = utils.shuffle(df)

    return shuffled_df

#####################################################################

# Test 이미지 DataFrame 만들기
'''
cat_test_dir = os.path.join(test_dir, 'cats')
dog_test_dir = os.path.join(test_dir, 'dogs')

total_test_dir = cat_test_dir + dog_test_dir

test_data = []

for test_img in os.listdir(total_test_dir):
    test_img_data = cv2.resize(cv2.imread(test_img, cv2.IMREAD_GRAYSCALE), (70,70))
    test_data.append(test_img_data.ravel())

test_df = pd.DataFrame(test_data)
'''
#####################################################################
# 데이터 만들기
train_df = create_train_data(train_dir)
val_df = create_train_data(val_dir)
test_df = create_train_data(test_dir)

#####################################################################
# 독립변수 종속변수 구분
train_x = train_df.drop('label', axis=1, inplace=False).values
train_t = train_df['label'].values

# 아무 그림 하나만 보기
plt.imshow(train_x[10:11].reshape(70,70), cmap='gray')
plt.show()

# validation용 data
val_x = val_df.drop('label', axis=1, inplace=False).values
val_t = val_df['label'].values

# test용 data
test_x = test_df.drop('label', axis=1, inplace=False).values
test_t = test_df['label'].values

# 정규화
scaler = MinMaxScaler()
scaler.fit(train_x)
norm_train_x = scaler.transform(train_x)
norm_val_x = scaler.transform(val_x)
```



> - 자체 CNN

```python
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Flatten, Dense, Conv2D, MaxPooling2D, Dropout
from tensorflow.keras.optimizers import Adam

# Tensor Layer

model = Sequential()

# Conv 1st layer
model.add(Conv2D(filters=64,
                 kernel_size=(3,3),
                 activation='relu',
                 padding='same',
                 input_shape=(70,70,1)))

# Pooling Layer
model.add(MaxPooling2D(pool_size=(2,2)))

# Conv 2nd layer
model.add(Conv2D(filters=64,
                 kernel_size=(3,3),
                 activation='relu',
                 padding='same'))

# Pooling Layer
model.add(MaxPooling2D(pool_size=(2,2)))

# Conv 3rd layer
model.add(Conv2D(filters=64,
                 kernel_size=(3,3),
                 activation='relu',
                 padding='same'))
# Pooling Layer
model.add(MaxPooling2D(pool_size=(2,2)))

# FC Layer
# input
model.add(Flatten())

# Dropout
model.add(Dropout(rate=0.5))

# hidden
model.add(Dense(units=128,
                activation='relu'))
# output
model.add(Dense(units=1,
                activation='sigmoid'))

print(model.summary())
```

```python
# 학습
# compile
model.compile(optimizer=Adam(learning_rate=1e-3),
              loss='binary_crossentropy',
              metrics='accuracy')

# fit
history = model.fit(norm_train_x.reshape(-1,70,70,1),
                    train_t,
                    batch_size=128,
                    epochs=20,
                    verbose=1,
                    validation_data=(norm_val_x.reshape(-1,70,70,1), val_t))
```

```python
# 그래프 그리기
train_acc = history.history['accuracy']
val_acc =history.history['val_accuracy']
 
train_loss = history.history['loss']
val_loss = history.history['val_loss']

# accuracy
plt.plot(train_acc, c='b', label='Training Accuracy')
plt.plot(val_acc, c='r', label='Validation Accuracy')
plt.legend()
plt.show()

# loss
plt.plot(train_loss, c='b', label='Training loss')
plt.plot(val_loss, c='r', label='Validation loss')
plt.legend()
plt.show()
```

```python
# test 데이터 평가
norm_test_x = scaler.transform(test_x)
print(model.evaluate(norm_test_x.reshape(-1,70,70,1), test_t))
```



## Transfer Learning

- `전이학습 (Transfer Learning)`

  - 특성추출 (Feature Extraction)

    : Pretrained Network를 이용해서 우리 이미지에 대한 Feature Map 추출 ==> FC Layer에 입력으로 넣어서 학습

    - ==> 추출한 결과(Feature Map)를 nd array로 저장하고 이 데이터를 FC Later에 입력하여 사용
    - ==> 상대적으로 학습 속도가 빠르다.

  - `Fine tuning` : Pretrained Network를 우리 model에 포함해서 계속 반복해서 학습 (Dens층 위에 쌓아서 학습한다는 의미)

    - Pretrained Network를 이용하는 또 다른 방법
    - Pretrained Network의 parameter를 모두 학습에 동결시키지 않고
    - 몇개의 conv layer를 해제해서 학습에 적용될 수 있도록(update 되도록)
    - 상위 layer (== FC Layer와 가까이 있는 layer) 몇개만 (약 2~3개)

#### Fine Tuning의 절차

1. Pretrained Network를 우리가 만들 model에 추가한다.
2. Pretrained Network(==Base Network) parameter 전체를 동결한다.
3. 새로 추가한 FC Layer 학습
4. Base Network의 일부분 layer를 동결에서 해제
5. 동결을 해제한 layer와 FC layer를 다시 학습

```python
# 라이브러리
import os
import matplotlib.pyplot as plt
from tensorflow.keras.applications import EfficientNetB0, MobileNetV2, VGG16
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Flatten, Dense, Dropout, Conv2D, MaxPooling2D
from tensorflow.keras.optimizers import Adam, RMSprop

# 이미지 데이터 불러오기
base_dir = '/content/drive/MyDrive/Cat_Dog/cat_dog_small'
train_path = os.path.join(base_dir, 'train')
val_path = os.path.join(base_dir, 'validation')
test_path = os.path.join(base_dir, 'test')

# ImageGenerator option
BATCH_SIZE = 20
IMG_SIZE = (100,100)

# 각 용도별 generator
train_gen = ImageDataGenerator(rescale=1/255)
val_gen = ImageDataGenerator(rescale=1/255)
test_gen = ImageDataGenerator(rescale=1/255)

# 각 이미지 generator
train_img_gen = train_gen.flow_from_directory(train_path,
                                             target_size=IMG_SIZE,
                                             batch_size=BATCH_SIZE,
                                             classes=['cats', 'dogs'],
                                             class_mode='binary')
val_img_gen = val_gen.flow_from_directory(val_path,
                                          target_size=IMG_SIZE,
                                          batch_size=BATCH_SIZE,
                                          classes=['cats', 'dogs'],
                                          class_mode='binary')
test_img_gen = test_gen.flow_from_directory(test_path,
                                            target_size=IMG_SIZE,
                                            batch_size=BATCH_SIZE,
                                            classes=['cats', 'dogs'],
                                            class_mode='binary')
```



> - 모델 만들기

```python
mobile_model = MobileNetV2(weights='imagenet',
                           include_top=False,
                           input_shape=(100,100,3))

# 먼저 사용할 pretrained network model 가중치 update 비활성화
mobile_model.trainable = False

# 분류기 모델 만들고 합체
model = Sequential()

model.add(mobile_model)

model.add(Flatten())

model.add(Dense(128, activation='relu'))

model.add(Dropout(0.5))

model.add(Dense(1, activation='sigmoid'))

print(model.summary())

# 컴파일
model.compile(optimizer=RMSprop(2e-5),
             loss='binary_crossentropy',
             metrics=['accuracy'])
# 학습
history = model.fit(train_img_gen,
                    steps_per_epoch=50,
                    epochs=20,
                    verbose=1,
                    validation_data=val_img_gen,
                    validation_steps=50)
```



> - fine tuning 전 그래프 그리기

```python
# fine tuning 전 그래프 그리기
train_loss = history.history['loss']
val_loss = history.history['val_loss']

train_accuracy = history.history['accuracy']
val_accuracy = history.history['val_accuracy']

fig = plt.figure(figsize=(20,5))
loss_graph = fig.add_subplot(1,2,1)
acc_graph = fig.add_subplot(1,2,2)

loss_graph.plot(train_loss, c='r', label='train_loss')
loss_graph.plot(val_loss, c='b', label='val_loss')
loss_graph.legend()

acc_graph.plot(train_accuracy, c='r', label='train_accuracy')
acc_graph.plot(val_accuracy, c='b', label='val_accuracy')
acc_graph.legend()

plt.show()
```



> - Fine Tuning

```python
# ver.1
mobile_model.trainable = True

for layer in mobile_model.layers[:150] :
    layer.trainable = False
```

```python
# ver.2
mobile_model.trainable = True

for layer in mobile_model.layers :
    if layer.name in ['block_16_project', 'block_16_project_BN', 'Conv_1', 'Conv_1_bn']:
        layer.trainable = True
    else:
        layer.trainable = False
```

```python
# 모델 학습하는 layer 개수 확인
len(mobile_model.trainable_variables)
```



> - Fine Tuning 후 re 컴파일 & 학습

```python
model.compile(optimizer=RMSprop(1e-6),
             loss='binary_crossentropy',
             metrics=['accuracy'])
history = model.fit(train_img_gen,
                    steps_per_epoch=50,
                    epochs=10,
                    verbose=1,
                    validation_data=val_img_gen,
                    validation_steps=50)
```



> - 다시 그래프 그려보기

```python
# fine tuning 전 그래프 그리기
train_loss = history.history['loss']
val_loss = history.history['val_loss']

train_accuracy = history.history['accuracy']
val_accuracy = history.history['val_accuracy']

fig = plt.figure(figsize=(20,5))
loss_graph = fig.add_subplot(1,2,1)
acc_graph = fig.add_subplot(1,2,2)

loss_graph.plot(train_loss, c='r', label='train_loss')
loss_graph.plot(val_loss, c='b', label='val_loss')
loss_graph.legend()

acc_graph.plot(train_accuracy, c='r', label='train_accuracy')
acc_graph.plot(val_accuracy, c='b', label='val_accuracy')
acc_graph.legend()

plt.show()
```



### Test Data 정확도 확인

```python
# test data의 정확도
test_loss, test_acc = model.evaluate(test_img_gen, verbose=1)
print('test data의 accuracy :', test_acc)
```



### 실제 이미지 예측

```python
import cv2

def predict_cat_dog(path):
    img = cv2.resize(cv2.imread(path), (100,100))
    img = img/255
    pred = model.predict(img.reshape(-1, 100, 100, 3))
    result = int(pred.ravel()[0])

    if result == 0 :
        answer = '고양이'
        print('고양이')
    else:
        answer = '강아지'
        print('강아지')

    return answer 

path = '/content/drive/MyDrive/Google Colab/dog.1006.jpg'
answer = predict_cat_dog(path)
```













