### ë‰´ëŸ°

> - ìš°ë¦¬ì˜ ë‡ŒëŠ” ì´ì „ neuronìœ¼ë¡œë¶€í„° ì…ë ¥ì‹ í˜¸ë¥¼ ì „ë‹¬ë°›ì•„ì„œ ë˜ ë‹¤ë¥¸ ì‹ í˜¸ë¥¼ ë°œìƒì‹œí‚¤ëŠ” ì¼ì„ í•œë‹¤.
> - ì…ë ¥ê°’ì— ë¹„ë¡€í•´ì„œ ì¶œë ¥ê°’ì„ ë‚´ë³´ë‚´ëŠ” í˜•íƒœê°€ ì•„ë‹ˆë‹¤.
> - ì…ë ¥ê°’ì— ê°€ì¤‘ì¹˜(w)ë¥¼ ê³±í•œ í›„ ëª¨ë‘ ë”í•´ì„œ íŠ¹ì • í•¨ìˆ˜ë¥¼ ì´ìš©í•˜ì—¬ thresholdeë¥¼ ë„˜ëŠ”ì§€ í™•ì¸!
> - ==> ì„ê³„ì ì„ ë„˜ìœ¼ë©´ ì¶œë ¥ê°’ ë°œìƒ
> - `íŠ¹ì • í•¨ìˆ˜` ë€.. Activation Function (`sigmoid`, `softmax` etc.)
> - í•˜ë‚˜ì˜ Neuronì´ í•˜ë‚˜ì˜ logistic ì´ë‹¤.



### ì´ë¯¸ì§€ ë°ì´í„°

> - ì´ë¯¸ì§€ ì´ë£¨ê³  ìˆëŠ” ê°€ì¥ ê¸°ë³¸ ë‹¨ìœ„ : **`Pixel`** (í•´ìƒë„) ==> í•´ìƒë„ â¬†ï¸ -> pixel ê°œìˆ˜ â¬†ï¸
> - ì´ë¯¸ì§€ëŠ” ìš°ë¦¬ê°€ ì¼ë°˜ì ìœ¼ë¡œ ì‚¬ìš©í•˜ëŠ” `ë°ì¹´ë¥´íŠ¸ ì¢Œí‘œê³„`ì™€ ë‹¤ë¥¸ **`ì´ë¯¸ì§€ ì¢Œí‘œê³„`** ë¥¼ ì‚¬ìš©í•œë‹¤.
> - ==> **`Matrix ì¢Œí‘œê³„ (í–‰ë ¬ ì¢Œí‘œê³„)`**
> - 2ì°¨ì› ì´ë¯¸ì§€(M Ã— N)ë¥¼ ndarrayë¡œ í‘œí˜„ ==> **`pixel [ì„¸ë¡œ(M), ê°€ë¡œ(N)]`**
> - â­ ì„¸ë¡œìª½ ì•„ë˜ë¡œ ë‚´ë ¤ê°ˆìˆ˜ë¡ ìˆ«ìê°€ ì¦ê°€í•œë‹¤.

> - **`gray-Image(í‘ë°± ì´ë¯¸ì§€)`**
>   - ê° pixelì˜ ê°’ì„ 0~255 ê°’ìœ¼ë¡œ í‘œí˜„
>     - 1 pixelì— 8bitë¥¼ ì‚¬ìš©í•˜ê¸° ë•Œë¬¸ì— 2^8 = 256ê°œ
>   - 2ì°¨ì›
> - **`color Image(ì»¬ëŸ¬ ì´ë¯¸ì§€)`**
>   - ê° pixelì— 3ê°œì˜ channelì´ í¬í•¨
>   - ê° channelì€ ë¹›ì˜ 3ì›ìƒ‰ (R,G,B)
>   - **`3ì°¨ì›`**
>   - ğŸ’— Red : 0~255 (8bit) / ğŸ’š Green : 0~255 (8bit) / ğŸ’™ Blue : 0~255 (8bit)
>   - `'24bit'` ==> `True Color`
>   - `JPG` file â–¶ï¸ 3 channel (RGB)
>   - `PNG` file â–¶ï¸ 4 channel (RGB + Î±) (Î±:íˆ¬ëª…ë„)

```python
# ë¼ì´ë¸ŒëŸ¬ë¦¬
from PIL import Image
import numpy as np
import matplotlib.pyplot as plt

# ì´ë¯¸ì§€ ë¡œë“œ
img_path = '/content/drive/MyDrive/Google Colab/dog.1006.jpg'
img = Image.open(img_path)
plt.imshow(img)
plt.show()

# ì´ë¯¸ì§€ë¥¼ ìˆ«ì pixelê°’ìœ¼ë¡œ ë³€ê²½
pixel = np.array(img)

# ì´ë¯¸ì§€ sizeì™€ shape í™•ì¸
print('ì´ë¯¸ì§€ì˜ í¬ê¸° : {}'.format(img.size))
# ==> ì´ë¯¸ì§€ì˜ í¬ê¸° : (499, 500) == (ê°€ë¡œ, ì„¸ë¡œ)

print('ì´ë¯¸ì§€ì˜ shape : {}'.format(pixel.shape))
# ì´ë¯¸ì§€ì˜ shape : (500, 499, 3) == (ì„¸ë¡œê¸¸ì´, ê°€ë¡œ, ê° pixelë‹¹ rgb 3ê°œ ê°€ì§€ê³  ìˆë‹¤.)

# ì‹¤ì œ ê°’ì„ í•œ ë²ˆ ë³´ì
print('xì¢Œí‘œ:{}, yì¢Œí‘œ:{}ì¸ pixel ê°’:{}'.format(100,200,pixel[200, 100]))
# xì¢Œí‘œ:100, yì¢Œí‘œ:200ì¸ pixel ê°’:[115  96  89] == [R, G, B]
# pixel ê°’ ì¤„ ë•Œ ì¡°ì‹¬í•˜ì! pixel[200,100] == pixel[ì„¸ë¡œ(y), ê°€ë¡œ(x)]

# ì´ë¯¸ì§€ size ì¤„ì—¬ë³´ê¸°
img_resize = img.resize((50, 50))
plt.imshow(img_resize)
plt.show()
```



### í‘ë°± ì´ë¯¸ì§€ ë³€ë™ ë°©ë²•

#### #1

```python
# 3ì°¨ì› ê·¸ëŒ€ë¡œ ì‚¬ìš©í•˜ëŠ” ë°©ë²• == ëª¨ë“  ê°’ í‰ê· ìœ¼ë¡œ ëŒ€ì²´

# í‘ë°± ì´ë¯¸ì§€ 3ì°¨ì› ë°ì´í„°ë¡œ í‘œí˜„
# ê° pixelì˜ RGBê°’ì˜ í‰ê· ! êµ¬í•´ì„œ ê°ê°ì˜ R G B ê°’ìœ¼ë¡œ ì„¤ì •
gray_pixel = pixel.copy()

# y= ì„¸ë¡œ / x = ê°€ë¡œ
for y range(gray_pixel.shape[0]):
    for x in range(gray_pixel.shape[1]):
        gray_pixel[y,x] = int(np.mean(gray_pixel[y,x]))
        # <<< í•´ë‹¹ pixelì˜ ìš”ì†Œ 3ê°œì§œë¦¬(RGBê°’) vector
        # ë¸Œë¡œë“œìºìŠ¤íŒ… ë˜ë©´ì„œ ê° rgb ê°’ì´ ëª¨ë‘ í‰ê· ê°’ìœ¼ë¡œ ëŒ€ì²´ëœë‹¤.
        # [76 76 76] ëª¨ë‘ ì´ ê°’ìœ¼ë¡œ setting

plt.imshow(gray_pixel)
plt.show()
```



#### #2

```python
# 2ì°¨ì›ìœ¼ë¡œ í‘ë°± ì´ë¯¸ì§€ í‘œí˜„

# rgb ê°’ ì¤‘ì— 1ê°œë§Œ ê°€ì ¸ì™€ì„œ ê·¸ëƒ¥ ê°’ìœ¼ë¡œ í‘œí˜„í•˜ê¸° (rgb ê°’ì´ vector ë²—ì–´ë‚˜)

gray_2d_pixel  = gray_pixel[:,:,0]
print(gray_2d_pixel.shape) # (426, 640) 2ì°¨ì›

plt.imshow(gray_2d_pixel) 
# plt.imshow()ëŠ” 3ì°¨ì› imageë¥¼ ë°›ì•„ì„œ ë³´ì—¬ì£¼ëŠ”ê±°ë‹¤!
# ê·¸ëŸ¬ë‹¤ë³´ë‹ˆ cmap ì§€ì • ì•ˆí•´ì£¼ë©´ ì•„ë˜ì²˜ëŸ¼ ì´ë¯¸ì§€ê°€ ë‚˜ì˜¨ë‹¤.
plt.show()

##################################################################

plt.imshow(gray_2d_pixel, cmap='gray') 
plt.show()
# cmap='gray' ì´ ê°’ì„ ì£¼ë©´ ì •ìƒì ì¸ í‘ë°± ì´ë¯¸ì§€ë¥¼ ë³´ì—¬ì¤€ë‹¤.
```



### Teachable Machine

> - íŒŒì¼ë¡œ í•™ìŠµ ë° í‰ê°€





### CNN (ë°”ë‹ë¼ ë‚ ê²ƒì˜...)

> - ì´ë¯¸ì§€ ë°ì´í„° ì „ì²˜ë¦¬

```python
# ë¼ì´ë¸ŒëŸ¬ë¦¬
import numpy as np
import pandas as pd
import os
import cv2
from sklearn import utils
from sklearn.preprocessing import MinMaxScaler


# íŒŒì¼ ê²½ë¡œ
train_dir = '/content/drive/MyDrive/Cat_Dog/cat_dog_small/train'
val_dir = '/content/drive/MyDrive/Cat_Dog/cat_dog_small/validation'
test_dir = '/content/drive/MyDrive/Cat_Dog/cat_dog_small/test'

# labeling í•¨ìˆ˜ (ê³ ì–‘ì´=0, ê°œ=1)
# img = íŒŒì¼ ì´ë¦„
def labeling(img):
    class_name = img.split('.')[0]
    if class_name == 'cat': return 0
    elif class_name == 'dog': return 1
    
# ì´ë¯¸ì§€ íŒŒì¼ì„ pixel dataë¡œ ë°”ê¾¸ëŠ” í•¨ìˆ˜
def create_train_data(directory):
    
    # label dataì™€ pixel data ë‹´ì„ ë³€ìˆ˜
    t_data = []
    x_data = []

    cat_dir = os.path.join(directory, 'cats')
    dog_dir = os.path.join(directory, 'dogs')

    total_img = os.listdir(cat_dir) + os.listdir(dog_dir)

    for img in total_img:

        label_data = labeling(img)

        if img.split('.')[0] == 'cat':
              path = os.path.join(cat_dir, img)
        else:
              path = os.path.join(dog_dir, img)

        # ì´ë¯¸ì§€ íŒŒì¼ nd.arrayë¡œ ë¶ˆëŸ¬ì˜¤ê¸° (cv2.imread())
        # í˜•íƒœë§Œ í•„ìš”í•´ì„œ í‘ë°±ìœ¼ë¡œ ë¶ˆëŸ¬ì˜¤ê¸° (cv2.IMREAD_GRAYSCALE)
        # ì´ë¯¸ì§€ pixel size ì¡°ì •í•˜ê¸°
        img_data = cv2.resize(cv2.imread(path, cv2.IMREAD_GRAYSCALE), (70,70))

        t_data.append(label_data)
        x_data.append(img_data.ravel())
        # ==> img_data ì´ë¯¸ì§€ shapeì´ (70,70), ì¦‰ 2ì°¨ì›
        # ==> ì´ê²Œ ê·¸ëŒ€ë¡œ ë“¤ì–´ê°€ë©´ ì°¨ì› í•˜ë‚˜ ë” ìˆì–´ì„œ ê²°êµ­ 3ì°¨ì›... ê·¸ë˜ì„œ 1ì°¨ì›ìœ¼ë¡œ ë°”ê¿”ì£¼ê¸°(ravel())

    # labeling Data ==> dataframeìœ¼ë¡œ ë§Œë“¤ê¸°
    t_df = pd.DataFrame({
        'label': t_data
    })

    # ì´ë¯¸ì§€ í”½ì…€ data ==> dataframeìœ¼ë¡œ ë§Œë“¤ê¸°
    x_df = pd.DataFrame(x_data)

    # 2ê°œ dataframe í•©ì¹˜ê¸° (í–‰ ê°œìˆ˜ê°€ ê°™ì•„ì•¼ í•œë‹¤?)
    df = pd.merge(t_df, x_df, left_index=True, right_index=True)

    # utils.shuffle() ==> pandas dataframe í–‰ì„ shuffle í•œë‹¤.
    shuffled_df = utils.shuffle(df)

    return shuffled_df

#####################################################################

# Test ì´ë¯¸ì§€ DataFrame ë§Œë“¤ê¸°
'''
cat_test_dir = os.path.join(test_dir, 'cats')
dog_test_dir = os.path.join(test_dir, 'dogs')

total_test_dir = cat_test_dir + dog_test_dir

test_data = []

for test_img in os.listdir(total_test_dir):
    test_img_data = cv2.resize(cv2.imread(test_img, cv2.IMREAD_GRAYSCALE), (70,70))
    test_data.append(test_img_data.ravel())

test_df = pd.DataFrame(test_data)
'''
#####################################################################
# ë°ì´í„° ë§Œë“¤ê¸°
train_df = create_train_data(train_dir)
val_df = create_train_data(val_dir)
test_df = create_train_data(test_dir)

#####################################################################
# ë…ë¦½ë³€ìˆ˜ ì¢…ì†ë³€ìˆ˜ êµ¬ë¶„
train_x = train_df.drop('label', axis=1, inplace=False).values
train_t = train_df['label'].values

# ì•„ë¬´ ê·¸ë¦¼ í•˜ë‚˜ë§Œ ë³´ê¸°
plt.imshow(train_x[10:11].reshape(70,70), cmap='gray')
plt.show()

# validationìš© data
val_x = val_df.drop('label', axis=1, inplace=False).values
val_t = val_df['label'].values

# testìš© data
test_x = test_df.drop('label', axis=1, inplace=False).values
test_t = test_df['label'].values

# ì •ê·œí™”
scaler = MinMaxScaler()
scaler.fit(train_x)
norm_train_x = scaler.transform(train_x)
norm_val_x = scaler.transform(val_x)
```



> - ìì²´ CNN

```python
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Flatten, Dense, Conv2D, MaxPooling2D, Dropout
from tensorflow.keras.optimizers import Adam

# Tensor Layer

model = Sequential()

# Conv 1st layer
model.add(Conv2D(filters=64,
                 kernel_size=(3,3),
                 activation='relu',
                 padding='same',
                 input_shape=(70,70,1)))

# Pooling Layer
model.add(MaxPooling2D(pool_size=(2,2)))

# Conv 2nd layer
model.add(Conv2D(filters=64,
                 kernel_size=(3,3),
                 activation='relu',
                 padding='same'))

# Pooling Layer
model.add(MaxPooling2D(pool_size=(2,2)))

# Conv 3rd layer
model.add(Conv2D(filters=64,
                 kernel_size=(3,3),
                 activation='relu',
                 padding='same'))
# Pooling Layer
model.add(MaxPooling2D(pool_size=(2,2)))

# FC Layer
# input
model.add(Flatten())

# Dropout
model.add(Dropout(rate=0.5))

# hidden
model.add(Dense(units=128,
                activation='relu'))
# output
model.add(Dense(units=1,
                activation='sigmoid'))

print(model.summary())
```

```python
# í•™ìŠµ
# compile
model.compile(optimizer=Adam(learning_rate=1e-3),
              loss='binary_crossentropy',
              metrics='accuracy')

# fit
history = model.fit(norm_train_x.reshape(-1,70,70,1),
                    train_t,
                    batch_size=128,
                    epochs=20,
                    verbose=1,
                    validation_data=(norm_val_x.reshape(-1,70,70,1), val_t))
```

```python
# ê·¸ë˜í”„ ê·¸ë¦¬ê¸°
train_acc = history.history['accuracy']
val_acc =history.history['val_accuracy']
 
train_loss = history.history['loss']
val_loss = history.history['val_loss']

# accuracy
plt.plot(train_acc, c='b', label='Training Accuracy')
plt.plot(val_acc, c='r', label='Validation Accuracy')
plt.legend()
plt.show()

# loss
plt.plot(train_loss, c='b', label='Training loss')
plt.plot(val_loss, c='r', label='Validation loss')
plt.legend()
plt.show()
```

```python
# test ë°ì´í„° í‰ê°€
norm_test_x = scaler.transform(test_x)
print(model.evaluate(norm_test_x.reshape(-1,70,70,1), test_t))
```



## Transfer Learning

- `ì „ì´í•™ìŠµ (Transfer Learning)`

  - íŠ¹ì„±ì¶”ì¶œ (Feature Extraction)

    : Pretrained Networkë¥¼ ì´ìš©í•´ì„œ ìš°ë¦¬ ì´ë¯¸ì§€ì— ëŒ€í•œ Feature Map ì¶”ì¶œ ==> FC Layerì— ì…ë ¥ìœ¼ë¡œ ë„£ì–´ì„œ í•™ìŠµ

    - ==> ì¶”ì¶œí•œ ê²°ê³¼(Feature Map)ë¥¼ nd arrayë¡œ ì €ì¥í•˜ê³  ì´ ë°ì´í„°ë¥¼ FC Laterì— ì…ë ¥í•˜ì—¬ ì‚¬ìš©
    - ==> ìƒëŒ€ì ìœ¼ë¡œ í•™ìŠµ ì†ë„ê°€ ë¹ ë¥´ë‹¤.

  - `Fine tuning` : Pretrained Networkë¥¼ ìš°ë¦¬ modelì— í¬í•¨í•´ì„œ ê³„ì† ë°˜ë³µí•´ì„œ í•™ìŠµ (Densì¸µ ìœ„ì— ìŒ“ì•„ì„œ í•™ìŠµí•œë‹¤ëŠ” ì˜ë¯¸)

    - Pretrained Networkë¥¼ ì´ìš©í•˜ëŠ” ë˜ ë‹¤ë¥¸ ë°©ë²•
    - Pretrained Networkì˜ parameterë¥¼ ëª¨ë‘ í•™ìŠµì— ë™ê²°ì‹œí‚¤ì§€ ì•Šê³ 
    - ëª‡ê°œì˜ conv layerë¥¼ í•´ì œí•´ì„œ í•™ìŠµì— ì ìš©ë  ìˆ˜ ìˆë„ë¡(update ë˜ë„ë¡)
    - ìƒìœ„ layer (== FC Layerì™€ ê°€ê¹Œì´ ìˆëŠ” layer) ëª‡ê°œë§Œ (ì•½ 2~3ê°œ)

#### Fine Tuningì˜ ì ˆì°¨

1. Pretrained Networkë¥¼ ìš°ë¦¬ê°€ ë§Œë“¤ modelì— ì¶”ê°€í•œë‹¤.
2. Pretrained Network(==Base Network) parameter ì „ì²´ë¥¼ ë™ê²°í•œë‹¤.
3. ìƒˆë¡œ ì¶”ê°€í•œ FC Layer í•™ìŠµ
4. Base Networkì˜ ì¼ë¶€ë¶„ layerë¥¼ ë™ê²°ì—ì„œ í•´ì œ
5. ë™ê²°ì„ í•´ì œí•œ layerì™€ FC layerë¥¼ ë‹¤ì‹œ í•™ìŠµ

```python
# ë¼ì´ë¸ŒëŸ¬ë¦¬
import os
import matplotlib.pyplot as plt
from tensorflow.keras.applications import EfficientNetB0, MobileNetV2, VGG16
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Flatten, Dense, Dropout, Conv2D, MaxPooling2D
from tensorflow.keras.optimizers import Adam, RMSprop

# ì´ë¯¸ì§€ ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸°
base_dir = '/content/drive/MyDrive/Cat_Dog/cat_dog_small'
train_path = os.path.join(base_dir, 'train')
val_path = os.path.join(base_dir, 'validation')
test_path = os.path.join(base_dir, 'test')

# ImageGenerator option
BATCH_SIZE = 20
IMG_SIZE = (100,100)

# ê° ìš©ë„ë³„ generator
train_gen = ImageDataGenerator(rescale=1/255)
val_gen = ImageDataGenerator(rescale=1/255)
test_gen = ImageDataGenerator(rescale=1/255)

# ê° ì´ë¯¸ì§€ generator
train_img_gen = train_gen.flow_from_directory(train_path,
                                             target_size=IMG_SIZE,
                                             batch_size=BATCH_SIZE,
                                             classes=['cats', 'dogs'],
                                             class_mode='binary')
val_img_gen = val_gen.flow_from_directory(val_path,
                                          target_size=IMG_SIZE,
                                          batch_size=BATCH_SIZE,
                                          classes=['cats', 'dogs'],
                                          class_mode='binary')
test_img_gen = test_gen.flow_from_directory(test_path,
                                            target_size=IMG_SIZE,
                                            batch_size=BATCH_SIZE,
                                            classes=['cats', 'dogs'],
                                            class_mode='binary')
```



> - ëª¨ë¸ ë§Œë“¤ê¸°

```python
mobile_model = MobileNetV2(weights='imagenet',
                           include_top=False,
                           input_shape=(100,100,3))

# ë¨¼ì € ì‚¬ìš©í•  pretrained network model ê°€ì¤‘ì¹˜ update ë¹„í™œì„±í™”
mobile_model.trainable = False

# ë¶„ë¥˜ê¸° ëª¨ë¸ ë§Œë“¤ê³  í•©ì²´
model = Sequential()

model.add(mobile_model)

model.add(Flatten())

model.add(Dense(128, activation='relu'))

model.add(Dropout(0.5))

model.add(Dense(1, activation='sigmoid'))

print(model.summary())

# ì»´íŒŒì¼
model.compile(optimizer=RMSprop(2e-5),
             loss='binary_crossentropy',
             metrics=['accuracy'])
# í•™ìŠµ
history = model.fit(train_img_gen,
                    steps_per_epoch=50,
                    epochs=20,
                    verbose=1,
                    validation_data=val_img_gen,
                    validation_steps=50)
```



> - fine tuning ì „ ê·¸ë˜í”„ ê·¸ë¦¬ê¸°

```python
# fine tuning ì „ ê·¸ë˜í”„ ê·¸ë¦¬ê¸°
train_loss = history.history['loss']
val_loss = history.history['val_loss']

train_accuracy = history.history['accuracy']
val_accuracy = history.history['val_accuracy']

fig = plt.figure(figsize=(20,5))
loss_graph = fig.add_subplot(1,2,1)
acc_graph = fig.add_subplot(1,2,2)

loss_graph.plot(train_loss, c='r', label='train_loss')
loss_graph.plot(val_loss, c='b', label='val_loss')
loss_graph.legend()

acc_graph.plot(train_accuracy, c='r', label='train_accuracy')
acc_graph.plot(val_accuracy, c='b', label='val_accuracy')
acc_graph.legend()

plt.show()
```



> - Fine Tuning

```python
# ver.1
mobile_model.trainable = True

for layer in mobile_model.layers[:150] :
    layer.trainable = False
```

```python
# ver.2
mobile_model.trainable = True

for layer in mobile_model.layers :
    if layer.name in ['block_16_project', 'block_16_project_BN', 'Conv_1', 'Conv_1_bn']:
        layer.trainable = True
    else:
        layer.trainable = False
```

```python
# ëª¨ë¸ í•™ìŠµí•˜ëŠ” layer ê°œìˆ˜ í™•ì¸
len(mobile_model.trainable_variables)
```



> - Fine Tuning í›„ re ì»´íŒŒì¼ & í•™ìŠµ

```python
model.compile(optimizer=RMSprop(1e-6),
             loss='binary_crossentropy',
             metrics=['accuracy'])
history = model.fit(train_img_gen,
                    steps_per_epoch=50,
                    epochs=10,
                    verbose=1,
                    validation_data=val_img_gen,
                    validation_steps=50)
```



> - ë‹¤ì‹œ ê·¸ë˜í”„ ê·¸ë ¤ë³´ê¸°

```python
# fine tuning ì „ ê·¸ë˜í”„ ê·¸ë¦¬ê¸°
train_loss = history.history['loss']
val_loss = history.history['val_loss']

train_accuracy = history.history['accuracy']
val_accuracy = history.history['val_accuracy']

fig = plt.figure(figsize=(20,5))
loss_graph = fig.add_subplot(1,2,1)
acc_graph = fig.add_subplot(1,2,2)

loss_graph.plot(train_loss, c='r', label='train_loss')
loss_graph.plot(val_loss, c='b', label='val_loss')
loss_graph.legend()

acc_graph.plot(train_accuracy, c='r', label='train_accuracy')
acc_graph.plot(val_accuracy, c='b', label='val_accuracy')
acc_graph.legend()

plt.show()
```



### Test Data ì •í™•ë„ í™•ì¸

```python
# test dataì˜ ì •í™•ë„
test_loss, test_acc = model.evaluate(test_img_gen, verbose=1)
print('test dataì˜ accuracy :', test_acc)
```



### ì‹¤ì œ ì´ë¯¸ì§€ ì˜ˆì¸¡

```python
import cv2

def predict_cat_dog(path):
    img = cv2.resize(cv2.imread(path), (100,100))
    img = img/255
    pred = model.predict(img.reshape(-1, 100, 100, 3))
    result = int(pred.ravel()[0])

    if result == 0 :
        answer = 'ê³ ì–‘ì´'
        print('ê³ ì–‘ì´')
    else:
        answer = 'ê°•ì•„ì§€'
        print('ê°•ì•„ì§€')

    return answer 

path = '/content/drive/MyDrive/Google Colab/dog.1006.jpg'
answer = predict_cat_dog(path)
```













