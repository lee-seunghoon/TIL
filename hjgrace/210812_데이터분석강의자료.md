# Numpy

> - 수치연산을 위한 파이썬 라이브러리 (Numeric Python)
> - 행렬 연산 기본
> - vector(1차원)나 matrix(2차원) 연산 편리성 제공
> - 넘파이 ==> 기본적인 자료구조 제공
> - ndarray(n-dimensional array) == n차원의 배열



## Numpy 생성

```python
import numpy as np

a = np.array([1,2,3,4,5])
b = [1,2,3,4,5]

print(a)
print(b)

print(type(a))
print(type(b))
```

`리스트와 넘파이 자료구조의 차이점 : ndarray는 모든 원소가 같은 데이터 type을 가져야 한다! & 리스트는 차원 개념이 없다`



## Numpy 구조 확인

```python
# 1차원
my_list = [1,2,3,4]
new_array = np.array(my_list)
print(new_array.dim)
print(new_array.shape)

# .dim ==> 차원의 수를 나타냄
# .shape ==> 각 차원과 요소의 개수를 tuple로 표현

# 2차원
my_list = [[1,2,3], [4,5,6]]
new_array = np.array(my_list)
print(new_array)
print(new_array.dim)
print(new_array.shape)

# 3차원
my_list = [[[1,2,3],[4,5,6]],[[7,8,9],[10,11,12]]]
new_array = np.array(my_list)
print(new_array)
print(new_array.dim)
print(new_array.shape) # ==> (2,2,3) ==> 2면 2행 3열
```



## Numpy 구조 변경

```python
# 1차원 ndarray 생성
my_list = [1,2,3,4]
new_array = np.array(my_list)
print(new_array)
print(new_array.shape)

# 1차원 -> 2차원 변경
new_array.shape = (2,2)
print(new_array)
print(new_array.shape)

# 2차원 -> 3차원 변경
new_array.shape = (4,1,1)
print(new_array)
print(new_array.shape)
```

### reshape

> - 새로운 ndarray를 만들지 않는다.
> - 변수를 새로 만들었지만 새로 만들어졌다기 보다 view로 만든 것
> - 메모리 아끼기 위해서 새로운 메모리 저장 공간을 만들지 않는다.
> - -1을 사용해 계상 없이 쉽게 변경 가능!

```python
# reshape 활용
# 이걸 더 많이 활용해요
new_array = new_array.reshape(2,2)
print(new_array)
print(new_array.shape)

# 더 많은 데이터
arr = np.arange(12)
print(arr)

# 복사본
arr1 = arr.reshape(3,4) # ==> 3행 4열 2차원 ndarray
print(arr1)
'''
[[ 0  1  2  3]
 [ 4  5  6  7]
 [ 8  9 10 11]]
'''

# -1 활용 reshape
# '-1'의 의미는 남은 것을 자동으로 배열하겠다는 의미
# 3행으로 맞춰서 만들고 열은 행 맞춘거와 data 고려해서 자동으로 구성
arr1 = arr.reshape(3,-1) # ==> 3행 4열
print(arr1)

# 반대로 열을 3열로 맞추고, 행을 자동 구성
arr1 = arr.reshape(-1,3) # ==> 4행 3열
print(arr1)

# 3차원
arr1 = arr.reshape(2,3,-1) # ==> 2면 3행 2열 
print(arr1)
'''
[[[0 1]
  [2 3]
  [4 5]]
    
[[6 7]
 [8 9]
 [10 11]]]
'''
```

### resize

> - ndarray의 형태를 변경할 수 있다.
> - 결과를 return하지 않고 원본을 바꾼다.
> - arr.resize(1,6) ==> 원본이 바뀜
> - 새로운 변수로 만들고 싶을 때는 ==> arr1 = `np.resize`(arr, (1, 6))
> - reshape()와 다르게 형태가 안맞아도 바꿀 수 있다. ==> 나머지 추가 요소는 0으로 채워짐 ==> 새로 만드는 개념이라서

```python
arr = np.array([[1,2,3],[4,5,6]])
arr1 = arr.resize(1,6)
print(arr1)
# ==> 기대값 : [[1 2 3 4 5 6]]
# ==> 실제값 : None  / 왜냐면 arr.resize()는 arr을 바꾸는거라서 return 값이 없어

# 다르게 적용
arr1 = np.resize(arr, (1,6))  # 얘는 return 값이 있겠지
# ==> numpy가 가지고 있는 resize 이용할거야!
# ==> 위 arr.resize랑 다르다.
print(arr1) # ==> [1 2 3 4 5 6]]

# 원본에 적용
arr.resize(3,4)
print(arr)
'''
[[1 2 3 4]
 [5 6 0 0]
 [0 0 0 0]]
'''

# 위와 차이점이 느껴지는가 / np method로 줬을 때는 추가 요소에 arr 안에 있는 값을 circle 시킨다.
arr2 = np.resize(arr, (3,4)) # ==> 추가
print(arr2) # ==> np.resize()는 요소가 circle이 발생!
'''
[[1 2 3 4 5]
 [6 1 2 3 4]
 [5 6 1 2 3]]
 
# 버리는 것도 가능하다!
# 굉장히 유연함
arr3 = np.resize(arr, (2,2)) # ==> 버림
print(arr3)
'''
[[1 2]
 [3 4]]
'''

```



## Numpy 데이터 유형

> - ndarray의 data type을 변경
> - int32 --> float64

```python
# ndarray(dtype : np.float64) 생성
arr = np.array([1,2,3,4,5], dtype = np.float64)
print(arr) # ==> [1. 2. 3. 4. 5.]

arr1 = np.array([1, 3.14, True, 'Hello']) 
# 이렇게 다른 데이터 type이 입력되면 자동으로 dtype이 <U32 로 설정
# 그리고 전체 모두 문자열로 바뀜
print(arr1) # ==> ['1' '3.14' 'True' 'Hello']
print(arr1.dtype) # ==> <U32

arr1 = np.array([1, 3.14, True, 'Hello'], dtype = np.object)
print(arr1) # ==> [1 3.14 True 'Hello']
print(arr1.dtype) # ==> object  / 각자가 객체 형태로 들어와 있음


# 데이터 타입 변경
arr = np.array([1.2, 2.3, 3.5, 5.4, 4.1, 5.7])
print(arr.dtype)  # ==> float64

arr = arr.astype(np.int32)
print(arr.dtype) # ==> int32
print(arr) # 정수로 바꿀 때 소수점 이하는 버린다.
# ==> [1 2 3 5 4 5]
```



## Numpy 유용한 함수 모음

> - np.arange()
> - ravel()
> - np.sum()
> - np.mean()
> - np.max()
> - np.min()
> - np.argmax()
> - np.argmin()
> - np.std()
> - np.sqrt()

```python
# np.arange
arr = np.arange(0,11,2)
# 0부터 10까지 2씩 건너뀌어서 ndarray 생성
print(arr)
# ==> [ 0  2  4  6  8 10]

# # arange는 기본 1차원 형식으로만 만들 수 있다
# 그래서 기본 만들고 원하는 shape로 reshape 줘야 한다.
print(arr.reshape(2,3)) # reshape는 view만 생성!
'''
[[ 0  2  4]
 [ 6  8 10]]
'''

# ravel()
# 어떤 차원의 배열이든 무조건 1차원으로 바꾼다.
# 이것도 copy된게 아니라 view가 return 된다!
arr1 = arr.ravel()
print(arr1)
# ==> [0  2  4  6  8 10]

arr = np.arange(1,7,1).reshape(2,3).copy()

# sum()
print(np.sum(arr))
print(arr.sum())
print(arr.sum(axis=0))
print(arr.sum(axis=1))


# mean()
print(np.mean(arr))
print(arr.mean())
print(arr.mean(axis=0))
print(arr.mean(axis=1))

# max()
print(np.max(arr))
print(arr.max())
print(arr.max(axis=0))
print(arr.max(axis=1))

# min()
print(np.min(arr))
print(arr.min())

# argmax() & argmin()
print(arr.argmax())
print(np.argmin(arr))

# 표준편차
print(np.std(arr))

# 제곱근
print(np.sqrt(arr))
```

### random ndarray

> - np.random.normal()

```python
# np.random.normal()
# 정규분포에서 실수형태 난수를 추출

import numpy as np
import matplotlib.pyplot as plt
# matplotlib 모듈 안에 있는 pyplot 클래스 이용

my_mean = 50 # 평균값
my_std = 2   # 표준편차

# 1차원 형태로 평균 50, 표준편차 2의 정규분포에 속한 난수를 추출한다
arr = np.random.normal(my_mean, my_std, (1000,)) 
# (평균, 표준편차, 요소개수 몇개 줄건지)
print(arr)
# ==> [48.79017376 52.94437454 46.62254331 ... 50.45626116 50.34343596 48.44195045]

# 위 수치를 히스토그램으로 그려보기
plt.hist(arr, bins=100)
# bins = 최대값과 최소값 사이를 100 영역으로 쪼갠다.
plt.show # ==> 그래프 출력하는 명령어
```

> - np.random.rand()

```python
# 0 이상 1 미만의 실수를 난수로 추출
# 균등분포로 난수 추출
# np.random.rand(d0, d1, d2, d3, ...)
# d0 = 1차원 요소 개수 / d1 = 2차원 요소 개수

import numpy as np
import matplotlib.pyplot as plt

arr = np.random.rand(10000)
print(arr)
# ==> 0과 1사이 난수 10000개 1차원 ndarray로 생성 

arr1 = np.random.rand(10,10)
print(arr1)
# ==> 10행 10열짜리 2차원 ndarray 생성

plt.hist(arr, bins=100)
plt.show
```

> - np.random.randn()

```python
# 표준 정규분포에서 실수 형태로 난수 추출
# 표준 정규분포(평균=0, 표준편차 =1)

arr = np.random.randn(10000) # ==> 10000 : 난수 10,000개 생성
print(arr)
'''
[ 1.43029222 -0.13987281 -1.48331412 ... -0.24107083  0.13395994
 -1.74265075]
'''

plt.hist(arr, bins=100)
plt.show
```

> - np.random.randint()

```python
# 균등분포로 정수 표본을 추출
# np.random.randint(low, high, shape)

arr = np.random.randint(10,100,(100,))
# ==> 10부터 99 수 중에서 매번 정수를 난수로 100개 뽑아 1차원 ndarray 만들어줘
print(arr)
# ==> [28 31 29 ... 74 47 56]
# ==> 난수여서 출력할 때마다 다른 값이 나온다.

plt.hist(arr, bins =10)
plt.show
```

> - np.random.random()

```python
# 0 이상 1미만의 실수를 난수로 추출
# np.random.rand()와 똑같은 것을 추출
# 사용 방식은 조금 다르다
# np.random.random((10000,)) ==> shape를 준다!

arr = np.random.random((10000,))
print(arr)
# [0.63932662 0.52270155 0.56998666 ... 0.67892132 0.5877172  0.37877959]

plt.hist(arr, bins = 100)
plt.show
```

> - np.random.shuffle()

```python
# 이미 만들어진 ndarray 데이터 순서를 random하게 바꾸고 싶을때 사용

arr = np.arange(10)
print(arr) # ==> [0 1 2 3 4 5 6 7 8 9]
np.random.shuffle(arr)
print(arr)
# ==> [4 9 6 2 1 8 5 7 0 3] / 마구 섞임
```



## Numpy Indexing



#### Numpy `1차원`  `Indexing/ Slicing`

```python
import numpy as np

arr = np.arange(10,20,1)
print(arr)

for idx, val in enumerate(arr):
    print('index:{}, value:{}'.format(idx, val))
    
    
# 인덱싱
# 첫번째 출력
print(arr[0])
# 중간 출력
print(arr[5])
# 마지막 출력
print(arr[-1])

# 슬라이싱
print(arr[0:2]) # ==> [0 1]
print(arr[:-1]) # ==> 맨 마지막 요소만 제외하고 슬라이싱!
print(arr[1:4:2]) # ==> 1부터 3까지 2칸 건너뛰면서 출력
print(arr[::-1])  # ==> [4 3 2 1 0]  거꾸로

```



#### Numpy `2차원`  `Indexing/ Slicing`

```python
arr = np.arange(1,17,1)
arr.resize((4,4))
print(arr)

# 인덱싱
print(arr[1,1]) # 2행 2열 ==> 일반적인 2차원 indexing
print(arr[1,:]) 
# ==> 2행의 처음부터 끝까지 열
# ==> [5 6 7 8] shape이 중요하다! 이건 2차원인가?
print(arr[1,:].shape) # ==> 아니 1차원 / ==> (4,)

# 슬라이싱
print(arr[1:3,:])
'''
[[ 5  6  7  8]
 [ 9 10 11 12]]
'''

# 2차원에서 1차원 인덱싱처럼 사용하면 행이 출력된다.
# 열만 인덱싱 할 수 없다
print(arr[0]) # 1행 전체를 출력
print(arr[0,:]) # 위와 이것과 같다
```



#### `Boolean mask`

```python
# 원본 ndarray와 shape이 같다.
# 요소 값을 모두 boolean(True, False) 값으로 구성
# boolean mask를 이용 해서 indexing
# 형태 : [ True True False False True]

print(arr % 2) 
# ==> [0 0 1 1 0 0 0 0 1 1]

print(arr % 2 == 0) 
# ==> [ True  True False False  True  True  True  True False False]

# ==> 이게 boolean mask
# ==> 이 것을 가지고 indexing 한다.

print(arr[arr%2 == 0])
# ==> [ 6 12 10 12  6 16]
# ==> boolean mask에서 True 인것만 뽑아준다
# ==> 짝수만 뽑아준다.

print(arr[arr%2==1])
# ==> [13  9  1 17]
# ==> boolean mask에서 홀수를 True로 주도록 설정
# ==> 홀수만 뽑아준다.
```



#### `Fancy indexing`

```python
# ndarray에 index배열(list형식)을 전달하여 배열요소를 참조
# ndarray 요소중 규칙성 없고, 연속성 없이 원하는 것만 뽑고싶을 때
# 즉, [1 2 3 4 5] 에서 2, 4, 5 뽑고 싶을 때
# 일반 indexing도 slicing 안된다.

arr = np.arange(1,6,1)
print(arr) # ==> [1 2 3 4 5]

# arr ndarray에서 2, 4, 5 뽑고싶다. 규칙성, 연속성 없이
print(arr[[1,3,4]])  # ==> [2 4 5]

print(arr[[0,2],2])
print(arr[[0,2],2:3])

# fancy indexing 중복 사용 오류
# ==> 1,3행의 1,3열 data를 가져오고 싶은데...
# 다차원에서 fancy indexing 중복 사용 오류

'''
[0 10] ==> error
'''

# 위와 같은 경우 numpy가 함수 하나 제공
# np.ix_() ==> 다차원에서도 fancy indexing 중복 적용 가능
print(arr[np.ix_([0,2],[0,2])])
'''
[[ 0  2]
 [ 8 10]]
'''
```



---



## `Pandas`

> - #### Numpy를 기본으로 `Series`와 `DataFrame`이라는 자료구조을 정의해서 사용
>
> - #### `Series` : 동일한 데이터 타입의 복수개의 성분으로 구성 (`ndarray`와 비슷하다)
>
> - ####  `DataFrame` : Table 형식으로 데이터를 저장하는 자료구조 (`Excel`과 비슷하다)

---

### `Series`

```python
# 항상 1차원! ndarray의 알파 더한 거지만. 정확히 말하자면, ndarray의 vector만을 수용한다.
# 같은 데이터 타입이 들어온다. (ex. 문자열이면 문자열 / 정수면 정수 / 실수면 실수)

import numpy as np
import pandas as pd

s = pd.Series([1,2,3,4,5,6], dtype = np.float64)  # ==> pandas의 series를 만듦 
print(s)  # ==> ndarray의 vector 즉, 1차원이다!
'''
0    1.0
1    2.0
2    3.0
3    4.0
4    5.0
5    6.0
dtype: float64
'''
print('Series의 값만 가져오고 싶어요 : {}'.format(s.values)) # series의 값들을 ndarray로 바꿔서
# ==> Series의 값만 가져오고 싶어요 : [1. 2. 3. 4. 5. 6.]

print('Series의 index만 가져오고 싶어요 : {}'.format(s.index))
# ==> Series의 index만 가져오고 싶어요 : RangeIndex(start=0, stop=6, step=1)
# ==> RangeIndex 라는 class type의 객체를 return해줌. (python의 range와 비슷하다고 생각하면 됨)
```



> - `index`

```python
import numpy as np
import pandas as pd

# Series index 직접 지정
s = pd.Series([1,5,8,10],
             dtype=np.int32,
             index=['a','b','c','d']) # ==> 문자열로 index 지정
print(s)
'''
a     1
b     5
c     8
d    10
dtype: int32
'''

# 5라는 값을 출력하려면 어떻게 해야 하나요?
print(s['b']) # ==> 5
print(s[1]) # ==> 숫자 index도 가능하다. / index가 변경되도 숫자 index 기본으로 가능!

################################################################################

# 정렬

# 인덱스을 기준으로 내림차순 정렬 방법
s = pd.Series([11,21,33,True,'55'], dtype=np.object, index=['a','c','e','g','h'])
print(s.sort_index(ascending=False))
'''
h      55
g    True
e      33
c      21
a      11
dtype: object
'''

# 값(vlaues)을 기준을 오름차순 정렬방법
s1 = pd.Series([2,1,9,7,3,5], dtype = np.int32 , 
               index = ['audi','honda','ford','huyndai','porche','benz'])
print(s1.sort_values(ascending = True))
'''
honda      1
audi       2
porche     3
benz       5
huyndai    7
ford       9
dtype: int32
'''

################################################################################

# Series index 같은 것으로 지정할 경우
# 같은 index끼리 묶어서 series 형태로 return!

s = pd.Series([1,5,8,10],
             dtype=np.int32,
             index=['a','b','a','d'])
print(s)
'''
a     1
b     5
a     8
d    10
dtype: int32
'''

print(s['a']) # ==> 값을 다 같이 묶어서 Series로 return해주네...
'''
a    1
a    8
dtype: int32
'''
```



> - `slicing`

```python
# slicing은 원본과 똑같은 data type으로 출력
# Series에서 slicing했기 때문에 Series 형식으로
# 지정한 index로 slicing할 때 ==> 끝에 준 index가 포함되서 슬라이싱 된다. (기존 slicing은 끝 값이 exclusive)

# 지정한 index로 slicing할 때!

s = pd.Series([1,5,8,10],
             dtype=np.int32,
             index=['a','b','c','d'])

print(s[0:3]) # slicing은 원본과 똑같은 data type으로 출력
              # Series에서 slicing했기 때문에 Series 형식으로
'''
a    1
b    5
c    8
dtype: int32
'''

print(s['a':'d']) # ==> 지정한 index로 slicing할 때!
                  # ==> 끝에 준 index가 포함되서 슬라이싱 된다.
'''
a     1
b     5
c     8
d    10
dtype: int32
'''
```



> - `boolean indexing` & `fancy indexing`

```python
import pandas as pd

s = pd.Series([1,5,8,10],
             dtype=np.int32,
             index=['a','b','c','d'])

print(s[[1,3]]) # Fancy indexing 가능
'''
b     5
d    10
dtype: int32
'''

print(s[['d','a']])
'''
d    10
a     1
dtype: int32
'''

print(s[s%2==0]) # boolean indexing 가능
'''
c     8
d    10
dtype: int32
'''

print(s.sum()) # 집계함수 사용 가능
```



### `Series` 이용해서 DB 만들기

> - `A 공장`의 2020-01-01부터 10일간 생산량을 Series로 저장
> - 생산량은 평균이 50이고, 표준편차가 5인 정규분포에서 랜덤하게 생성(정수)
> - index 형식 : 2020-01-01

---

> - `B 공장`의 2020-01-01부터 10일간 생산량을 Series로 저장
> - 생산량은 평균이 70이고, 표준편차가 8인 정규분포에서 랜덤하게 생성(정수)
> - index 형식 : 2020-01-01

---

> - 날짜별로 모든(A공장, B공장)의 생산량의 합계를 구하세요.

```python
import numpy as np
import pandas as pd
from datetime import datetime, timedelta  
# ==> datetime 이라는 패키지에서 datetime, timedelta 라는 모듈 사용
# ==> 날짜를 편하게 구하기 위해서!
# ==> 외부 module 이라서 conda든 pip든 install datetime 해야함!

np.random.seed(1)
start_day = datetime(2020,1,1)
print(start_day) # ==>  2020-01-01 00:00:00

'''
# 날짜연산은 일반적으로 함수를 이용하여 연, 월, 주, 일 단위로 증감 가능
* 일 단위 증감 : timedelta 모듈
* 연, 월 단위 증감 :
* 주 단위 증감 :
'''
factory_A = pd.Series([int(x) for x in np.random.normal(50,5,(10,))],
                     index = [ start_day + timedelta(days= i) for i in range(10)]) 
print(factory_A)
'''
2020-01-01    58
2020-01-02    46
2020-01-03    47
2020-01-04    44
2020-01-05    54
2020-01-06    38
2020-01-07    58
2020-01-08    46
2020-01-09    51
2020-01-10    48
dtype: int64
'''

factory_B = pd.Series([int(x) for x in np.random.normal(50,5,(10,))],
                     index = [ start_day + timedelta(days= i) for i in range(10)]) 
print(factory_B)
'''
2020-01-01    57
2020-01-02    39
2020-01-03    48
2020-01-04    48
2020-01-05    55
2020-01-06    44
2020-01-07    49
2020-01-08    45
2020-01-09    50
2020-01-10    52
dtype: int64
'''

# Series의 사칙연산은  같은 index 끼리 이뤄진다.
print(factory_A + factory_B)
'''
2020-01-01    115
2020-01-02     85
2020-01-03     95
2020-01-04     92
2020-01-05    109
2020-01-06     82
2020-01-07    107
2020-01-08     91
2020-01-09    101
2020-01-10    100
dtype: int64
'''

# Index가 겹치지 않는 경우는?
factory_A = pd.Series([int(x) for x in np.random.normal(50,5,(10,))],
                     index = [ start_day + timedelta(days= i) for i in range(10)]) 

factory_B = pd.Series([int(x) for x in np.random.normal(50,5,(10,))],
                     index = [ datetime(2020,1,5) + timedelta(days= i) for i in range(10)]) 

print(factory_A + factory_B)
'''
2020-01-01      NaN
2020-01-02      NaN
2020-01-03      NaN
2020-01-04      NaN
2020-01-05    100.0
2020-01-06     94.0
2020-01-07     95.0
2020-01-08     90.0
2020-01-09     94.0
2020-01-10    101.0
2020-01-11      NaN
2020-01-12      NaN
2020-01-13      NaN
2020-01-14      NaN
dtype: float64
'''
# ==> NaN  ==> Not a Number 숫자가 아니다
```



### dict를 이용해 `Series` 만들기

> - pd.Series객체.name ==> Series에 이름 부여
> - Series객체.index ==> Series index 불러오기 or 수정 가능
> - Series객체.index.name ==> Series index에 이름 부여

```python
import pandas as pd

my_dict = {'서울':1000 , '인천':2000, '수원':3000}
s = pd.Series(my_dict)
print(s)
'''
서울    1000
인천    2000
수원    3000
dtype: int64
'''

# Series에 이름을 줄 수 있다.
s.name = '지역별 가격 데이터'
print(s) # ==> Name: 지역별 가격 데이터, dtype: int64

print(s.index)
# ==> Index(['서울', '인천', '수원'], dtype='object')  
# ==> 이건 Index라는 객체, class를 의미!! list는 아니다! 
# ==> But! list와 유사하게 사용할 수 있다.


# ==> index를 바꿀 수도 있다. list 형태로 가능!
s.index = ['Seoul', 'Inchon', 'Suwon']


# index에도 Title을 붙여줄 수 있다.
s.index.name = 'Region'

print(s)
'''
Region
Seoul     1000
Inchon    2000
Suwon     3000
Name: 지역별 가격 데이터, dtype: int64
'''
```



---



### `DataFrame` 생성

```python
import numpy as np
import pandas as pd

my_dict = {'name':['강감찬', '신사임당', '홍길동', '이순신'],
           'year':[2011, 2012, 2015, 2008],
           'score':[4.5, 2.5, 3.1, 3.7]}

# Series 만들기
s = pd.Series(my_dict)
print(s)

# 시리즈와 비교해서 데이터프레임 보기
df = pd.DataFrame(my_dict)
print(df)

# ==> print는 삐뚤삐뚤 보기 불편 so, display 사용
display(df)
```



### `DateFrame` 정보 확인

```python
print(df.shape) # ==> (4, 3)
print(df.size)  # ==> 12 (이 dataframe의 값이 몇개가 들어 있어??)
print(df.ndim)  # ==> 2 (무조건 2차원이다. dataframe은!)
print(df.index) # ==> RangeIndex(start=0, stop=4, step=1)
print(df.columns) # ==> 현재 data의 column 명을 ... 
                  # ==> Index(['name', 'year', 'porit'], dtype='object')
print(df.values) # ==> 값들만 2차원 ndarray로 출력해준다.

# 데이터 전반적인 정보
df.info()
df.describe()

```



### DataFrame `Indexing` & `Slicing`

> - column(열)은 `Indexing` 과 `Fancy indexing` 만 가능
> - row(행)은 `slicing` 만 가능

```python
# Column(열)을 기준으로 인덱싱
data = {'이름':['홍길동', '신사임당', '강감찬', '이순신','정약용'],
        '학과':['컴퓨터', '철학', '경영', '영어영문','스포츠과학'],
        '학년':[1,2,2,4,3],
        '학점':[1.3,2.4,3.5,2.7,4.1]}
df = pd.DataFrame(data,
                  columns = ['학과','이름','학년','학점'],   # ==> 컬럼 순서를 지정해 줄 수 있다
                  index = ['1번','2번','3번','4번','5번'])  # ==> 인덱스를 지정할 수 있다.

# 특정 column 가져오기
print(df['이름']) # ==> 시리즈로 가져온다.

# fancy indexing 기번을 사용하면 컬럼을 기준으로 가져온다
display(df[['이름','학점']]) # ==> fancy indexing은 slicing이랑 비슷해서, 원본 data type을 그대로 계승!

# 새로운 column을 생성하고, 새로운 값을 넣고 싶을 때
df['등급'] = 'A' 
display(df)

# 값들을 직접 줄 수도 있고, 결측값을 줄 수도 있다.
df['등급'] = ['A', 'B','C','D',np.nan]
display(df)

##########################################################################################

# 슬라이싱은 row(행)을 기준으로 가져온다.
display(df[1:3]) # ==> view 형식인거 잊지 말자
display(df[1:]) # 1행부터 끝까지

# display(df[[1,3]]) 
# err==> record에 대한 fancy indexing 안된다! (column에서는 됐는데...)

# row(행) indexing 진짜 안될까?
print(df['1번']) # <== 이것도 안된다! column에 관한 거였으니깐(단일 indexing)
display(df['2번':'5번']) # ==> slicing을 이용해서 record slice 가능하다.
display(df['3번':])
display(df['1번':'1번'])

#display(df['2번':-1]) # err ==> 숫자 index와 지정 index를 혼용해서 사용 불가
#display(df[['1번','2번']]) # err ==> 당연 fancy indexing도 안된다!
```



### DataFrame `boolean indexing`

```python
data = {'이름':['홍길동', '신사임당', '강감찬', '이순신','정약용'],
        '학과':['컴퓨터', '철학', '경영', '영어영문','스포츠과학'],
        '학년':[1,2,2,4,3],
        '학점':[1.3,2.4,3.5,2.7,4.1]}
df = pd.DataFrame(data,
                  columns = ['학과','이름','학년','학점'],
                  index = ['1번','2번','3번','4번','5번'])

display(df['학점']>4.0) # ==> Series 형식으로
                        #==> broadcasting 되서 boolean mask 형태 만들어 진다.
                        # ==> boolean mask 가져올 때, index 지정한거 자동으로 매칭
'''
1번    False
2번    False
3번    False
4번    False
5번     True
Name: 학점, dtype: bool
'''

# boolean indexing
# 전체 column
df[df['학점']>4.0]

# 특정 column
df['이름'][df['학점']>4.0]

df[['이름', '학과']][df['학점']>4.0]
```



### DataFrame `.loc()` & `.iloc()`

> - `.loc[]` : 텍스트
> - `.iloc[]` : 숫자

```python
# loc[행, 열]
display(df.loc['1번':'3번','이름']) # ==> 1번에서 3번 행의 이름 column만

display(df.loc['1번':'3번','이름':'학년']) # df.loc[행,열] 
# ==> column은 단독적으로 slicing을 지원하지 않는다.
# ==> But!! .loc[] 에서는 column에서 slicing 가능하다

display(df.loc['1번':'3번',['이름','학점']])
# ==> fancy indexing도 가능

# 행,열 모두 fancy 가능
df.loc[['1번', '3번'], ['이름', '학점']]

# 행만 fancy 열은 slicing 가능
df.loc[['1번', '3번'], '이름':'학점']
```

```python
# iloc[행, 열]
display(df.iloc[0:3,1])

display(df.iloc[0:3,1:])

display(df.iloc[0:3,[1,3]])

display(df.iloc[[0,2],[1,3]])

display(df.iloc[[0,2],1:])
```



### DataFrame 특정 Column & Row `삭제`

```python
# .drop() 을 통해서 ==> column(열)을 지울 수 있고, record(행)도 지울 수 있다.
#  DataFrame안 데이터를 삭제하는 경우

#  ==> 원본 삭제하는 경우 : inplace =True
#  ==> 원본은 보존하고 삭제처리된 복사본 생성하는 경우 : inplace =False


# Column(열) 삭제

new = df.drop('학년', axis = 1, inplace=False)
display(new)

new = df.drop(['학년', '이름'], axis = 1, inplace=False)
display(new)

df.drop('학년', axis = 1, inplace=False)
display(df) # ==> 원본은 그대로

df.drop('학년', axis = 1, inplace=True)
display(df) # ==> 원본 변경




# Row(행) 삭제

new = df.drop('1번', axis = 0, inplace=False) # ==> 행이 삭제
display(new) # ==> 복사본 출력

df.drop('2번', axis=0, inplace = True) # ==> axis를 명시하지 않으면 
                                       # ==> default는 axis = 0
                                       # ==> inplace = False 가 default
display(df) # ==> inplace = True 는 view를 생성 == 즉, 원본 변동

##############################################

# Fancy indexing을 drop 삭제할 행에 사용할 수 있다.
df.drop(['1번','3번'],axis=0, inplace=True)
display(df)

##############################################

# slicing은 drop()에서 삭제할 행에 사용할 수 없다!!
# df.drop('4번':'5번', axis=0, inplace =True) ==> Error
# display(df) # ==> Error
```



### NaN 존재 여부 확인

```python
import numpy as np
import pandas as pd

np.random.seed(1)
arr = np.random.randint(0,10,(6,4))
df = pd.DataFrame(arr)

df.columns = ['A','B', 'C','D']
df.index = pd.date_range('20200101','20200106')

df['E'] = [7, np.nan, 4, np.nan, 2, np.nan]

nan_df = df.isnull()
display(nan_df)

# E column의 값이 NaN인 행들을 찾아서 해당행의 모든 column값을 출력
display(df[nan_df['E']])
```





### NaN 처리

> - 데이터 속에서 NaN이 상대적으로 적을 때는 지우는 게 유용
> - NaN은 데이터분석이나 머신러인, 딥러닝 전에 반드시 처리해야하는 값!!
> - But 일반적으로 NaN 지우면 데이터가 많이 줄어서 여러 문제 발생 가능성
> - NaN 지우다가 전체 행을 지우게 되서, 유의미한 데이터도 잃어버릴 수 있다.
> - 다른 나머지 값들의 평균값으로 대체 하는 게 무난함, 하지만 case by case

```python
import numpy as np
import pandas as pd

data = [[2, np.nan],
        [7,-3],
        [np.nan,np.nan],
        [1,-2]]

df = pd.DataFrame(data,
                  columns = ['one', 'two'],
                  index = ['a','b','c','d'])

#############################################
# dropna

new_df1 = df.dropna(how='any', axis=0)
new_df2 = df.dropna(how='any', axis=1)
display(new_df1)
display(new_df2)

#############################################
# fillna

df['one'] = df['one'].fillna(value=df['one'].min())

df['two'] = df['two'].fillna(value=df['two'].max())
```



### df.replace()

```python
import numpy as np
import pandas as pd

np.random.seed(1)
arr = np.random.randint(0,10,(6,4))
df = pd.DataFrame(arr)

df.columns = ['A','B', 'C','D']
df.index = pd.date_range('20200101','20200106')

df['E'] = [7, np.nan, 4, np.nan, 2, np.nan]

display(df.replace(np.nan, -100))
# ==> NaN 값을 찾아서 -100으로 바꿔주세요.
```



### DataFrame 정렬

```python
import numpy as np
import pandas as pd

df = pd.DataFrame(np.random.randint(0,10,(6,4)))
df.columns = ['A', 'B', 'C', 'D']
df.index = pd.date_range('20200101', periods=6)
display(df)

new_index = np.random.permutation(df.index) 
# ==> 원본은 변경하지 않고
# ==> 순서가 바뀐 복사본을 리턴한다.

df2 = df.reindex(index=new_index, columns=['B','A','D','C']) 
# ==> 원본은 안바뀐다!! 그래서 새로운 변수 df2 대입

display(df2)
# ==> index 순서가 바꼈고, column 순서까지 바꼈다.
```

```python
# 정렬은 기본적으로 axis를 기준으로 정렬
# index로 정렬!
# pandas.Dataframe.sort_index()

# ==> 행방향(세로)을 기준으로 오름차순!
# ==> record의 index가 정렬(날짜)
df2 = df2.sort_index(axis=0, ascending=True) 
display(df2)

# ==> 열방향(가로)를 기준으로 오름차순
# ==> column의 index가 정렬(A,B,C,D)
df3 = df2.sort_index(axis=1, ascending=True)
display(df3)

# 특정 column의 `값`을 정렬!

display(df2.sort_values(by=['B','A'])) 
# ==> B column을 우선 기준으로 값을 정렬하고
# ==> B column의 값이 동률이면, 다음'A' column 값을 기준으로 정렬한다.
```



### 기타 함수 - .unique() / .value_counts / .isin()

> - `.unique()`

```python
import numpy as np
import pandas as pd

np.random.seed(1)
df = pd.DataFrame(np.random.randint(0,10,(6,4)))
df.columns = ['A', 'B', 'C', 'D']
df.index = pd.date_range('20200101',periods = 6)
display(df)

df['E'] = ['AA','BB','CC','CC','AA','CC']
display(df)

# .unique()
# ==> 중복된 값을 제거!

print(df['E'].unique()) 
# ==> ndarray로 등장...
# ==> ['AA' 'BB' 'CC']
```



> - `.value_counts`

```python
import numpy as np
import pandas as pd

np.random.seed(1)
df = pd.DataFrame(np.random.randint(0,10,(6,4)))
df.columns = ['A', 'B', 'C', 'D']
df.index = pd.date_range('20200101',periods = 6)
display(df)

df['E'] = ['AA','BB','CC','CC','AA','CC']
display(df)

print(df['E'].value_counts())
# ==> 이건 또 Series로...
'''
CC    3
AA    2
BB    1
Name: E, dtype: int64
'''
```



> - `.isin()`

```python
import numpy as np
import pandas as pd

np.random.seed(1)
df = pd.DataFrame(np.random.randint(0,10,(6,4)))
df.columns = ['A', 'B', 'C', 'D']
df.index = pd.date_range('20200101',periods = 6)
df['E'] = ['AA','BB','CC','CC','AA','CC']
display(df)

# .isin()
# ==> 안에 있는 값이 있니?? 판단 (boolean)

print(df['E'].isin(['AA','BB']))
'''
2020-01-01     True
2020-01-02     True
2020-01-03    False
2020-01-04    False
2020-01-05     True
2020-01-06    False
Freq: D, Name: E, dtype: bool
'''


```



### merge()

```python
import numpy as np
import pandas as pd

data1 = {
    '학번' : [1,2,3,4],
    '이름' : ['홍길동', '신사임당', '아이유', '김현아'],
    '학년' : [2, 4, 1, 3]
}

data2 = {
    '학번' : [1,2,4,5],
    '학과' : ['컴퓨터', '철학', '심리', '영어영문'],
    '학점' : [3.5, 2.7, 4.0, 4.3]
}

df1 = pd.DataFrame(data1)
df2 = pd.DataFrame(data2)


# inner
df3 = pd.merge(df1, df2, on='학번', how = 'inner')
display(df3)
# ==> 결합할 수 있는 것만 결합해서 출력!
# ==> 매치할 기준에서 동일값이 없는 data는 자동으로 버린다. (== inner)
# 'how==inner'는 Default 값


# outer
df3 = pd.merge(df1, df2, on='학번', how = 'outer')
# ==>  how = 'outer' 
# ==> 'full outer'(full을 생략하고 있다.) 모든 DataFrame 다 가져와!
# ==> df끼리 매치되는 기준이 없어도 즉, 여기서는 '학번'이 같지 않는 것도 다 가져온다.
display(df3)

# left
df4 = pd.merge(df1, df2, on='학번', how = 'left')
# ==> how = 'left'
# ==> 왼쪽 DataFrame(df1)만 남는거 붙여와
display(df4)

# right
df5 = pd.merge(df1, df2, on='학번', how = 'right')
# ==> how = 'right'
# ==> 오른족 DataFrame(df2)만 남는거 붙여와
display(df5)
```

### 

### pd.merge() column명이 다를 경우

```python
data1 = {
    '학번' : [1,2,3,4],
    '이름' : ['홍길동', '신사임당', '아이유', '김현아'],
    '학년' : [2, 4, 1, 3]
}

data2 = {
    '학생학번' : [1,2,4,5],
    '학과' : ['컴퓨터', '철학', '심리', '영어영문'],
    '학점' : [3.5, 2.7, 4.0, 4.3]
}

df1 = pd.DataFrame(data1)
df2 = pd.DataFrame(data2)

display(pd.merge(df1, df2, left_on='학번', right_on='학생학번', how='inner'))
# ==> 'on'의 기준을 각 data별 column 명으로 제시해준다.
# ==> left_on = df1 / right_on = df2
# ==> 결과 값은 각각 column명으로 따로 나온다.
```



### pd.concat() 연결

```python
# 열방향으로 연결(axis=1)
import numpy as np
import pandas as pd

df1 = pd.DataFrame(np.arange(6).reshape(3,2),
                   index = ['a', 'b', 'd'],
                   columns = ['one', 'two'])

df2 = pd.DataFrame(np.arange(4).reshape(2,2),
                   index = ['a', 'c'],
                   columns = ['three', 'four'])


result = pd.concat([df1,df2], 
                   axis=1)
# ==> 얘는 결합(merge)하는게 아니라!
# ==> 연결할거야!!
# ==> 개수 제한 없이 연결 가능, merge는 2개만 가능!
display(result)


# sort 값을 주면 index가 정렬되서 출력
new_result = pd.concat([df1,df2], 
                       axis=1,
                       sort=True) # ==> index가 정렬된다.
display(new_result)

######################################################

# 행방향으로 연결(axis=0)
import numpy as np
import pandas as pd

df1 = pd.DataFrame(np.arange(6).reshape(3,2),
                   index = ['a', 'b', 'd'],
                   columns = ['one', 'two'])

df2 = pd.DataFrame(np.arange(4).reshape(2,2),
                   index = ['a', 'c'],
                   columns = ['three', 'four'])

result = pd.concat([df1,df2], 
                   axis=0)
display(result) 
# ==> 그냥 가져다 붙는다.
# Series는 index가 똑같아도 새로 생성한다.
```



### Groupby

```python
import numpy as np
import pandas as pd

my_dict = {
    '학과' : ['컴퓨터', '경영학과', '컴퓨터', '경영학과', '컴퓨터'],
    '학년' : [1,2,3,2,3],
    '이름' : ['홍길동', '신사임당', '김연아', '아이유', '강감찬'],
    '학점' : [1.5, 4.4, 3.7, 4.5, 4.2]
}
df = pd.DataFrame(my_dict)
display(df)

# '학과'를 기준으로 '학점'을 grouping
score = df['학점'].groupby(df['학과'])
display(score) 
# ==> <pandas.core.groupby.generic.SeriesGroupBy object at 0x00000255D82BD1C8>
# ==> 객체에 대한 메모리 주소만 나온다.

# 그룹 안 데이터 확인하고 싶을 때!
# ==> get_group() 사용!

# '컴퓨터'를 기준으로 group한 경우
display(score.get_group('컴퓨터'))
'''
0    1.5
2    3.7
4    4.2
Name: 학점, dtype: float64
'''

# '경영학과'를 기준으로 group한 경우
display(score.get_group('경영학과'))
'''
1    4.4
3    4.5
Name: 학점, dtype: float64
```

```python
# 각 조건대로 grouping 된 개수 출력

print(score.size())
'''
학과
경영학과    2
컴퓨터     3
Name: 학점, dtype: int64
```

```python
# 각 그룹의 평균을 구하라!

print(score.mean())
'''
학과
경영학과    4.450000
컴퓨터     3.133333
Name: 학점, dtype: float64
```

```python
import numpy as np
import pandas as pd

my_dict = {
    '학과' : ['컴퓨터', '경영학과', '컴퓨터', '경영학과', '컴퓨터'],
    '학년' : [1,2,3,2,3],
    '이름' : ['홍길동', '신사임당', '김연아', '아이유', '강감찬'],
    '학점' : [1.5, 4.4, 3.7, 4.5, 4.2]
}
df = pd.DataFrame(my_dict)
display(df)

# DataFrame 자체를 grouping!
score = df.groupby(df['학과'])

print(type(score)) 
# ==> <class 'pandas.core.groupby.generic.DataFrameGroupBy'>
# ==> DataFrameGroupBy 

print(score.get_group('경영학과'))
'''
	  학과  학년    이름   학점
1  경영학과   2   신사임당  4.4
3  경영학과   2     아이유  4.5
'''

print(score.size())
'''
학과
경영학과    2
컴퓨터     3
dtype: int64
'''

# 여기서 dept는 '학과' , group = '학과'로 묶인 dataFrame
# 첫번째, 경영학과 / 경영학과의 DataFrame data
# 두번째, 컴퓨터 / 컴퓨터 학과의  DataFrame data
for dept, group in score:
    print(dept)
    display(group)
```



## Quiz

> - contain() : 특정 글자를 포함하면 true/false

### Q1

```
각 사용자별 평균 평점
```

```python
import numpy as np
import pandas as pd

df = pd.read_csv('./ml-latest-small/ratings.csv')
rating = df['rating'].groupby(df['userId'])
print(rating.mean())
'''
userId
1      4.366379
2      3.948276
3      2.435897
4      3.555556
5      3.636364
         ...   
606    3.657399
607    3.786096
608    3.134176
609    3.270270
610    3.688556
Name: rating, Length: 610, dtype: float64
'''
```

```
각 영화별 평균 평점
```

```python
import numpy as np
import pandas as pd

df = pd.read_csv('./ml-latest-small/ratings.csv')
rating = df['rating'].groupby(df['movieId'])
rating_mean = rating.mean()


df_movies = pd.read_csv('./ml-latest-small/movies.csv')
df_movie_title = df_movies[['movieId','title']]
df_merge = pd.merge(df_movie_title, rating_mean, on = 'movieId', how = 'outer')
print(df_merge)
```



### Quiz2

```
평균 평점이 가장 높은(낮은) 영화 제목 출력
```

```python
import numpy as np
import pandas as pd

df = pd.read_csv('./ml-latest-small/ratings.csv')
rating = df['rating'].groupby(df['movieId'])

# movieId별 평점 평균
rating_mean = rating.mean()

df_movies = pd.read_csv('./ml-latest-small/movies.csv')

# 데이터 결합
df_combine = pd.merge(df_movies,rating_mean, on = 'movieId', how = 'outer')
# rating 기준으로 정렬 (기본 오름차순)
df_combine = df_combine.sort_values(by='rating')

```



### Quiz3

```
코미디 영화 중 평균 평점이 가장 높은(낮은) 영화 제목 출력
```

```python
import numpy as np
import pandas as pd

df = pd.read_csv('./ml-latest-small/ratings.csv')
rating = df['rating'].groupby(df['movieId'])

# movieId별 평점 평균
rating_mean = rating.mean()

df_movies = pd.read_csv('./ml-latest-small/movies.csv')

# 데이터 결합
df_combine = pd.merge(df_movies,rating_mean, on = 'movieId', how = 'outer')
# rating 기준으로 정렬 (기본 오름차순)
df_combine = df_combine.sort_values(by='rating')

# 장르 중에 Comedy 있는 영화만 추출
comedy = df_combine[df_combine['genres'].str.contains('Comedy')]

# comedy 장르 중 NaN 값 지우기
comedy.dropna(how='any', axis=0, inplace=True)

# 최소값 구한 후, 그 최소값만 가지는 값 빼와서 'title'로 오름차순 정렬
rating_min = comedy['rating'].min()
result = comedy[comedy['rating'] == rating_min]
display(result[['movieId','title','genres']].sort_values(by='title'))
```

