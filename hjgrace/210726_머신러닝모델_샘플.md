# 머신러닝 모델 비교



## 데이터

> - 약 80여개 칼럼 존재
> - 데이터 개수는 1,000개 내외 일듯
> - 정규화 안돼 있음



## 라이브러리

```python
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
# 교차검증, K-Fold cross validation 을 위한 라이브러리
from sklearn.model_selection import cross_val_score
# 선형 회귀 모델
from sklearn.linear_model import LinearRegression
# 로지스틱 회귀 모델
from sklearn.linear_model import LogisticRegression
# KNN 분류
from sklearn.neighbors import KNeighborsClassifier
# SVM
from sklearn.svm import LinearSVC
# 의사결정나무 모델
from sklearn.tree import DecisionTreeClassifier
# 랜덤포레스트
from sklearn.ensemble import RandomForestClassifier
# 통계값 라이브러리
import statsmodels.api as sm
# 히트맵을 위한
import seaborn as sns
from sklearn.metrics import confusion_matrix
```



## 데이터 로드

```python
path = './test.xlsx'
lsv18 = pd.read_excel(path, sheet_name=0, index_col=False)
lsv19 = pd.read_excel(path, sheet_name=1, index_col=False)
lsv20 = pd.read_excel(path, sheet_name=2, index_col=False)
```



## 데이터 전처리

```python
# 필요없는 컬럼 삭제
lsv18.drop(['사원번호', '비즈니스_mean', '피플_mean', '종합_mean', '질문항목별_mean'], axis=1, inplace=True)

# 7점 척도로 돼 있어서 5점 척도로 바꾸기
lsv18 = lsv18.iloc[:,:-1].apply(lambda x : x/7*5)

# 행의 전체 평균 구하기
lsv18['mean'] = lsv18.mean(axis=1)

# 각 구한 평균의 평균 값 구하기
lsv18['mean'].mean()

# 평균 보다 크면 1, 작으면 0 labeling 하기
lsv18['label'] = lsv18['mean'] > lsv18['mean'].mean()
lsv18['label'] = lsv18['label'].map(lambda x : int(x))
```



## 데이터 분리

> 1. train_test_split
> 2. Cross Validation



### 1. train_test_split

```python
# 독립변수 = X , 종속변수 = y
X = lsv18.iloc[:,:-2]
y = lsv18['label']

# test_size = 0.2 로 분리
train_X, test_X, train_y, test_y = train_test_split(X, y, test_size=0.2, random_state=0)
```



### 2. Cross Validation

```python
# 바로 cross validation 적용
from sklearn.model_selection import cross_val_score

score1 = cross_val_score(forest, X, y)
print(score1.mean())
```

```python
from sklearn.model_selection import KFold

cv = 5 # ==> Fold의 수
kfold = KFold(n_splits=cv, shuffle=True, random_state=0)
result = cross_val_score(forest, X, y, cv=kfold)
print('최종 accuracy :', result.mean())
```





## 데이터 통계값 확인

```python
x2 = sm.add_constant(X)
model = sm.OLS(y, x2)
result = model.fit()
result.summary()
```



## 모델 객체 생성

```python
lr = LinearRegression()
lgr = LogisticRegression()
svm = LinearSVC(random_state=1)
knn = KNeighborsClassifier(n_neighbors=10)
tree = DecisionTreeClassifier(random_state=2)
forest = RandomForestClassifier(n_estimators=50, random_state=3)
```



## 학습

```python
lr.fit(train_X, train_y)
lgr.fit(train_X, train_y)
svm.fit(train_X, train_y)
knn.fit(train_X, train_y)
tree.fit(train_X, train_y)
forest.fit(train_X, train_y)
```



## Score 계산

```python
print('선형회귀 정확도 : {:.2f}'.format(lr.score(test_X, test_y)))
print('로지스틱 정확도 : {:.2f}'.format(lgr.score(test_X, test_y)))
print('SVM 정확도 : {:.2f}'.format(svm.score(test_X, test_y)))
print('KNN 정확도 : {:.2f}'.format(knn.score(test_X, test_y)))
print('의사결정나무 정확도 : {:.2f}'.format(tree.score(test_X, test_y)))
print('랜덤포레스트 정확도 : {:.2f}'.format(forest.score(test_X, test_y)))
```



## Traing set, test set 정화도 그래프 비교

> - 예시 KNN

```python
train_acc = []
test_acc = []

for n in range(1,15):
    clf = KNeighborsClassifier(n_jobs=-1, n_neighbors=n)
    clf.fit(train_X, train_y)
    prediction = clf.predict(test_X)
    train_acc.append(clf.score(train_X, train_y))
    test_acc.append((prediction==test_y).mean())
    
# 그래프 그리기
plt.figure(figsize=(12,9))
plt.plot(range(1,15), train_acc, label='Train Set')
plt.plot(range(1,15), test_acc, label='Test Set')
plt.xlabel('n_neighbors')
plt.ylabel('accuracy')
plt.xticks(np.arange(0,16, step=1))
plt.legend()
plt.show()
```



## 히트맵

```python
# confusion matrix 만들기
cnf_metrix = metrics.confusion_matrix(y_test, y_pred)
print(cnf_metrix)

# 히트맵 속성 설정
class_names = ['good_leader', 'non_good_leader']
fig, ax = plt.subplots()
tick_marks = np.arange(len(class_names))
plt.xticks(tick_marks, class_names)
plt.yticks(tick_marks, class_names)

# 히트맨 생성
sns.heatmap(pd.DataFrame(cnf_metrix), annot=True, cmap='YlGnBu', fmt='g')
ax.xaxis.set_label_position("top")
plt.tight_layout()
plt.title("Confusion matrix", y=1.1)
plt.ylabel("Actual label")
plt.xlabel("Predict label")
plt.show()
```

