## 라이브러리

```python
import numpy as np
import pandas as pd
import re
from konlpy.tag import Okt
from sklearn.feature_extraction.text import CountVectorizer
from sklearn.feature_extraction.text import TfidfVectorizer
import nltk
import matplotlib.pyplot as plt
from matplotlib import font_manager, rc
from wordcloud import WordCloud
from collections import Counter
```



## 그래프 폰트 설정

```python
# 폰트 사이즈
plt.rcParams['font.size'] = 25
# 폰트 설정
plt.rcParams['font.family'] = 'Malgun Gothic'
# 화면크기 설정
plt.rcParams['figure.figsize'] = (16,18)
```



## 함수 모음

### 나이 분리 함수

```python
# 나이대 분리 함수
def age_split(age):
    if age < 20 :
        result = 1
    elif age < 30 :
        result = 2
    elif age < 40 :
        result = 3
    elif age < 50 :
        result = 4
    elif age < 60 :
        result = 5
    else:
        result = 6
        
    return result
```



### 지역 분리 함수

```python
# 지역 분리 함수
def location_split(location):
    if location in [1,4,8]:
        result = 1 # ==> 수도권
    elif location in [6, 10, 11, 17]:
        result = 2 # 충청권
    elif location in [5, 12, 13]:
        result = 3 # 전라권
    elif location in [2, 3, 7, 14, 15]:
        result = 4 # 경상권
    elif location in [9]:
        result = 5 # 강원권
    else:
        result = 6 # 제주
    return result
```



## 형태소 분석 Tokenize

```python
# okt 형태소 분석기 토크나이징
def tokenize(text):
    okt = Okt()
    tokens = okt.pos(text)

#     stop_words = ['있는', '하는', '생각', '합니다', '대한', '필요', '먼저'
#              '한다', '마음', '문제', '대통령', '위해', '않는', '의견', '나라']
#     tokens = [(word, tag) for word, tag in tokens if word not in stop_words]
    
    total_words = []
    for word, tag in tokens:
        if tag not in ['Josa', 'Suffix']:
            total_words.append(word)
    result = ' '.join(total_words)
    return result
```



## 빈도분석 함수

```python
# 빈도분석 함수
def count_vectorize(text, vectorizer):
    word_dict = sorted(vectorizer.vocabulary_.items())
    idx2word = {idx:word for word, idx in word_dict}
    
    total_word = []
    total_word.append((' ').join(text.values))
    
    count_matrix = count_vectorizer.transform(total_word)
    
    count_word = []
    count_vector = []
    
    for i in range(20,0,-1):
        count_word.append(idx2word[(-count_matrix.toarray()[0]).argsort()[i-1]])
        count_vector.append(count_matrix.toarray()[0][(-count_matrix.toarray()[0]).argsort()[i-1]]) 
    
    return count_word, count_vector
```



## TF-IDF 분석 함수

```python
# tf-idf 분석
def tfidf_data(text_data, stop_word, tfidf):
    _tokeniz = text_data.map(tokenize)
    
    _word = []
    for sentence in [text for text in _tokeniz.values]:
        for word in sentence.split(' '):
            if word not in stop_word:
                _word.append(word)
                
    _total_word = []
    _total_word.append(' '.join(_word))

    _tfidf_matrix = tfidf.transform(_total_word)
    
    # 단어사전 정렬
    word_dict = sorted(tfidf.vocabulary_.items())
    idx2word = {idx:word for word, idx in word_dict}
    
    _tfidf_word = []
    _tfidf = []
    for i in range(25,0,-1):
        _tfidf_word.append(idx2word[(-_tfidf_matrix.toarray()[0]).argsort()[i-1]])
        _tfidf.append(_tfidf_matrix.toarray()[0][(-_tfidf_matrix.toarray()[0]).argsort()[i-1]])

    return _tfidf_word, _tfidf
```



## 가로 막대 그래프 그리기

```python
# 가로 막대 그래프 그리기
def count_graph(word, vector, color, title):
    plt.barh(word, vector, label='단어 빈도', color=color)
    plt.ylabel('단어')
    plt.xlabel('빈도')
    plt.legend()
    plt.yticks(word)
    plt.title('{} 텍스트 빈도 분석 Top20'.format(title))
    plt.tight_layout()
    plt.savefig('{}.png'.format(title))
    plt.show()
```

