{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 내용정리"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> - 성경이란 특성상 개역개정이나 개역한글 버전을 사용하면 형태소 분석기에서 정확히 분리하기 어려울 것으로 예상해서 `쉬운성경` 버전을 사용했습니다.\n",
    "> - 아래 코드는 sample로 `창세기`만 분석해놨는데\n",
    "> - 아래 코드에 성경 리스트 데이터를 만들어 놔서 이 리스트를 활용해서 for문이든, 아님 원하는 성경 파트를 추출해서 해당 성경을 분석할 수 있습니다\n",
    "> - `빈도분석`과 `워드클라우드` 분석만 진행했습니다\n",
    "> - 워드 클라우드는 `image mask`를 이용할 수 있어서 새롭게 표현해봤습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 라이브러리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 정규표현식을 위한 라이브러리\n",
    "import re\n",
    "# 넘파이 & 판다스\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "# 그래프 시각화 라이브러리\n",
    "import matplotlib.pyplot as plt\n",
    "# 형태소 분석기 라이브러리\n",
    "from konlpy.tag import Okt\n",
    "# 빈도분석, tfidf 라이브러리\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "# 코사인 유사도 라이브러리\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "# 에러 메세지 처리 라이브러리\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore')\n",
    "\n",
    "# matplotlib 그래프 속성 설정\n",
    "plt.rcParams['font.family'] = 'Malgun Gothic'\n",
    "plt.rcParams['figure.figsize'] = (12,16)\n",
    "plt.rcParams['font.size'] = 20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 사용자 정의 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 텍스트 전처리 함수\n",
    "def prepro_text(data, stop_words):\n",
    "    # okt 형태소 분석기 객체 생성\n",
    "    okt = Okt()\n",
    "    # 텍스트 데이터 문자열로 통일\n",
    "    data = str(data)\n",
    "    \n",
    "    # 영문, 특수기호, 숫자 제거\n",
    "    text = re.sub(r'[^가-힣]', ' ', data)\n",
    "\n",
    "    prepro_words = []\n",
    "    # 품사 처리\n",
    "    for word, tag in okt.pos(text):\n",
    "        # josa와 suffix 품사 제외한 단어만 추가\n",
    "        if tag not in ['Josa', 'Suffix']:\n",
    "            prepro_words.append(word)\n",
    "    \n",
    "    # 한 문장으로 묶기\n",
    "    result = ' '.join(prepro_words)\n",
    "\n",
    "    return prepro_words\n",
    "\n",
    "\n",
    "# 빈도분석 후 결과 출력\n",
    "def count_analyze(texts, count_vec, cnt, color, title):\n",
    "    \n",
    "    # 빈도분석용 vectorizer 적합 시키기\n",
    "    count_vec.fit(texts)\n",
    "    \n",
    "    # 단어 사전 정렬\n",
    "    word_dict = sorted(count_vec.vocabulary_.items())\n",
    "    # {index : word} 형식으로 단어사전 만들기\n",
    "    idx2word = {idx:word for word, idx in word_dict}\n",
    "\n",
    "    # 전체 텍스트를 하나로 묶기\n",
    "    total_text = []\n",
    "    total_text.append(' '.join(texts.values))\n",
    "\n",
    "    # 앞에서 적합(fit) 시킨 vectorizer를 활용해서 전체 텍스트 백터화 하기\n",
    "    count_matrix = count_vec.transform(total_text)\n",
    "\n",
    "    count_word = []\n",
    "    count_vector = []\n",
    "    for i in range(cnt,0,-1):\n",
    "        # {index:word} 사전을 활용해서 제일 빈도높은 순서대로 단어 추출하기\n",
    "        count_word.append(idx2word[(-count_matrix.toarray()[0]).argsort()[i-1]])\n",
    "        # 빈도높은 횟수를 순서대로 추출하기\n",
    "        count_vector.append(count_matrix.toarray()[0][(-count_matrix.toarray()[0]).argsort()[i-1]])\n",
    "\n",
    "    # 추출한 단어와 빈도 확인하기\n",
    "    print(count_word)\n",
    "    print(count_vector)\n",
    "\n",
    "    # 가로 막대 그래프로 보여주기\n",
    "    plt.barh(count_word, count_vector, color=color)\n",
    "    plt.yticks(count_word)\n",
    "    plt.title(f'{title} 빈도 분석')\n",
    "    plt.show()\n",
    "\n",
    "    return count_word, count_vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 데이터 로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 파일 경로\n",
    "old_path = './쉬운성경/구약'\n",
    "new_path = './쉬운성경/신약'\n",
    "\n",
    "old_testament = os.listdir(old_path)\n",
    "new_testament = os.listdir(new_path)\n",
    "\n",
    "# 신약만 이름 순으로 정렬\n",
    "new_testament.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 구약 성경 데이터 프레임\n",
    "old_testament_df = pd.DataFrame(columns=['성경제목', '성경주소', '성경본문'])\n",
    "# 각 구약 성경 title 가져오기\n",
    "for title in old_testament:\n",
    "    # 각 성경 path 세팅하기\n",
    "    each_old = old_path + '/' + title\n",
    "    # 각 성경 텍스트를 데이터 프레임으로 가져오기\n",
    "    df = pd.read_table(each_old, encoding='cp949', names=['성경본문'])\n",
    "    # '.txt'기준으로 분리한 후 앞부분을 성경제목으로 세팅\n",
    "    df['성경제목'] = title.split()[1].strip('.txt')\n",
    "    # 성경본문 텍스트를 str 문자열 타입으로 변경\n",
    "    df['성경본문'] = df['성경본문'].astype(str)\n",
    "    # 성경주소가 본문과 띄어쓰기(' ')로 구분돼 있어서 그 기준으로 분리\n",
    "    df['성경주소'] = df['성경본문'].map(lambda x : x[ : x.find(' ')])\n",
    "    # 위와 같이 띄어쓰기(' ') 기준으로 뒷 부분이 성경 본문\n",
    "    df['성경본문'] = df['성경본문'].map(lambda x : x[x.find(' ')+1 :])\n",
    "    # 제목, 주소, 본문만을 기본 데이터 프레임으로 세팅\n",
    "    df = df[['성경제목', '성경주소', '성경본문']]\n",
    "    # 위에서 만든 old_testament_df 에 붙이기\n",
    "    old_testament_df = pd.concat([old_testament_df, df], axis=0, ignore_index=True)\n",
    "\n",
    "# 신약 성경 데이터 프레임\n",
    "new_testament_df = pd.DataFrame(columns=['성경제목', '성경주소', '성경본문'])\n",
    "# 각 신약 성경 title 가져오기\n",
    "for title in new_testament:\n",
    "    # 각 성경 path 세팅하기\n",
    "    each_new = new_path + '/' + title\n",
    "    # 각 성경 텍스트를 데이터 프레임으로 가져오기\n",
    "    df = pd.read_table(each_new, encoding='cp949', names=['성경본문'])\n",
    "    # '.txt'기준으로 분리한 후 앞부분을 성경제목으로 세팅\n",
    "    df['성경제목'] = title.split()[1].strip('.txt')\n",
    "    # 성경본문 텍스트를 str 문자열 타입으로 변경\n",
    "    df['성경본문'] = df['성경본문'].astype(str)\n",
    "    # 성경주소가 본문과 띄어쓰기(' ')로 구분돼 있어서 그 기준으로 분리\n",
    "    df['성경주소'] = df['성경본문'].map(lambda x : x[ : x.find(' ')])\n",
    "    # 위와 같이 띄어쓰기(' ') 기준으로 뒷 부분이 성경 본문\n",
    "    df['성경본문'] = df['성경본문'].map(lambda x : x[x.find(' ')+1 :])\n",
    "    # 제목, 주소, 본문만을 기본 데이터 프레임으로 세팅\n",
    "    df = df[['성경제목', '성경주소', '성경본문']]\n",
    "    # 위에서 만든 new_testament_df 에 붙이기\n",
    "    new_testament_df = pd.concat([new_testament_df, df], axis=0, ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 성경 리스트 정리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 구약 성경 리스트\n",
    "old_testament_list = []\n",
    "for title in old_testament:\n",
    "  old_testament_list.append(title[title.find(' ') + 1:title.find('.')])\n",
    "\n",
    "# 신양 성경 리스트\n",
    "new_testament_list = []\n",
    "for title in new_testament:\n",
    "  new_testament_list.append(title.split()[1].strip('.txt'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 빈도분석"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 창세기로 sample example\n",
    "for title in old_testament_list[:1]:\n",
    "  \n",
    "    # 각 성경별 본문 시리즈로 불러오기\n",
    "    each_old_testament = old_testament_df['성경본문'][old_testament_df['성경제목']== title]\n",
    "\n",
    "    # 각 텍스트 본문별 전처리\n",
    "    each_old_testament = each_old_testament.map(prepro_text)\n",
    "\n",
    "    # 불용어 사전\n",
    "    stop_words = ['하셨습니다', '그런데', '그', '그러자', '있는', '아니었고', '없이', '했습니다', '것', '내', '이',\n",
    "                    '입니다', '너', '네', '저', '나', '해', '그리고']\n",
    "\n",
    "    # CountVectorizer 이용하여 빈도분석\n",
    "    cnt_vectorizer = CountVectorizer(\n",
    "        stop_words = stop_words, # ==> 불용어사전 세팅\n",
    "        ngram_range = (1,1),    # ==> 1word ngram\n",
    "        max_features = 100,     # ==> 최대 특징\n",
    "        min_df = 50,            # ==> 최소 문서 빈도 설정\n",
    "    )\n",
    "\n",
    "    # 빈도분석으로 그래프로 단어, 빈도 수 추출하기\n",
    "    cntvec_word, cntvec_vec = analysis_by_CountVectorizer(each_old_testament,cnt_vectorizer, 20, 'tab:blue', '창세기')\n",
    "\n",
    "    # 워드클라우드에 맞게 데이터 모양 바꾸기\n",
    "    data_for_wordcloud = {word:vec for word, vec in zip(cntvec_word, cntvec_vec)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 이미지 적용한 워드클라우드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 적용할 이미지 path \n",
    "bible_img_path ='./open_book(1).png'\n",
    "# mask 세팅을 위한 코드\n",
    "bible_icon = Image.open(bible_img_path)\n",
    "bible_mask = Image.new('RGB', bible_icon.size, (255,255,255))\n",
    "bible_mask.paste(bible_icon,bible_icon)\n",
    "mask = np.array(bible_mask)\n",
    "\n",
    "# 이미지 마스크 적용한 워드클라우드\n",
    "wc = WordCloud(\n",
    "    font_path = 'Malgun Gothic',\n",
    "    width = 400,    # ==> 가로 크기\n",
    "    height = 400,   # ==> 세로 크기\n",
    "    background_color = 'white', # ==> 배경 색\n",
    "    max_words=100,  # ==> 최대 단어 세팅\n",
    "    mask = mask     # ==> 위에서 세팅한 마스크 적용\n",
    ")\n",
    "\n",
    "# 도화지 생성\n",
    "plt.figure(figsize=(10,10))\n",
    "# 위에서 만든 data_for_wordcloud를 집어 넣어준다.\n",
    "plt.imshow(wc.generate_from_frequencies(data_for_wordcloud).to_image())\n",
    "# 축은 사용하지 않는다.\n",
    "plt.axis('off')\n",
    "# 이미지 출력\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
