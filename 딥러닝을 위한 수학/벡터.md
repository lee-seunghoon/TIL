# 벡터

- 숫자를 원소로 가지는 리스트(list) or 배열(array)
- 벡터의 차원이란 원소의 개수를 의미
- 벡터란 공간에서 한 점을 나타낸다 
- 1차원 공간에서 벡터는 수직선 위 한 점(숫자)를 의미
- 2차원 공간에서 벡터는 좌표평면 상에 한 점(숫자)을 의미
- 3차원 공간에서 벡터 또한 (x,y,z) 축의 한 점(숫자)을 의미
- 일반적으로 멕터는 원점으로부터의 상대적인 위치를 의미하고
- 벡터에 연산을 진행하면 방향은 그대로이고 길이만 변한다(스칼라 곱으로 진행할 때)
- `스칼라 곱`이란 상수를 벡터에 곱해주는거라고 이해하면 됨.
- 벡터는 같은 모양을 가질 때, 덧셈, 뺄셈, 곱셈이 가능하다 (곱셈은 `성분곱`이라 표현)
- 두 벡터의 덧셈(+뺄셈)은 다른 벡터로부터 상대적 위치 이동을 의미한다.



# 벡터의 노름(norm)

- 원점에서 한 벡터까지의 `거리`를 의미

- L1 , L2 노름

- L1 노름은 각 성분의 변화량 절대값을 모두 더한다
  == 즉, 좌표축에 따라 이동하는 거리의 절대값을 더하면 된다

- L2 노름(유클리드 거리)은 실제 원점에서 벡터까지의 직선의 거리를 구한다
  == 피타고라스 정리 공식을 통해 점과 점 사이의 거리를 구한다고 이해하면 됨.

- L1, L2 노름 구하는 함수

  ```python
  # L1 norm
  def l1_norm(x):
      # 절대값 씌워주기
      x_norm = np.abs(x)
      # 모든 값 더하기
      x_norm = np.sum(x_norm)
      return x_norm
  
  # L2 norm
  # x에는 벡터가 들어간다
  def l2_norm(x):
      # 제곱
      x_norm = x * x
      # 벡터 전체 덧셈
      x_norm = np.sum(x_norm)
      # 제곱근 구하는 함수 (루트 씌워주기)
      x_norm = np.sqrt(x_norm)
      return x_norm
  ```



- 노름의 종류에 따라 `기하학적 성질`이 달라진다
- L1 노름은 Robust 학습, Lasso 회귀 같은 곳에 사용되고
- L2 노름은 Laplace 근사, Ridge 회귀에 사용된다
- 머신러닝에서 구현 모델의 특성에 따라 두 노름 모두 필요에 맞게 사용해서, 최적화, 정규화 작업을 진행한다.



# 벡터 사이의 거리

- 두 점 사이의 거리와 같다

- 두 벡터 사이의 거리는 두 벡터의 뺄셈 개념을 활용한다.

- x와 y 벡터 사이의 거리는 원점과 y 벡터에서 x벡터의 거리만큼 빼준 거리를 의미 (L1 노름 개념)

- 두 벡터 사이의 거리 이용하여 `각도`를 계산 ==> 제 2 코사인 법칙 이용 ==> 2차원에서 사용 가능 (L2 노름 적용)

- `내적` : 벡터들을 성분곱 한 후 모든 값을 더해주면 내적을 구할 수 있다.
  $$
  <x,y>(내적) = \sum_{i=1}^{d}{x_iy_i}
  $$
  

  ```python
  # 두 벡터 사이 거리 구하는 함수
  def cos_angle(x, y):
      # np.inner() 메써드를 활용해서 내적값 구하기
      v = np.inner(x, y) / (l2_norm(x) + l2_norm(y))
      # np.arccos() ==> cosine 각도를 역으로 취해주는 메써드
      # 역으로 취해야 우리가 원하는 거리가 나온다
      theta = np.arccos(v)
      return theta
  ```



- 내적은 정사영된 벡터의 길이와 관련 있다
- `정사영`이란 벡터의 그림자라고 생각할 수있다.
- `내적`은 두 벡터 사이의 `유사도`를 측정하는 데 사용된다.

